# -*- coding: utf-8 -*-
"""
ğŸš€ Windows NPUæœ€é©åŒ–æ©Ÿèƒ½

Windowsç’°å¢ƒã§ã®NPUï¼ˆNeural Processing Unitï¼‰æ¤œå‡ºãƒ»æœ‰åŠ¹åŒ–ãƒ»æœ€é©åŒ–
- AMD Ryzen AI NPUå¯¾å¿œ
- Intel NPUå¯¾å¿œ
- Qualcomm NPUå¯¾å¿œ
- DirectML NPUæœ€é©åŒ–
"""

import os
import sys
import subprocess
import platform
import psutil
import time
import torch
from typing import Dict, List, Optional, Tuple
import traceback

class WindowsNPUOptimizer:
    """Windows NPUæœ€é©åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.npu_info = {}
        self.npu_available = False
        self.npu_type = None
        self.directml_available = False
        self.onnx_session = None  # ONNX Runtime ã‚»ãƒƒã‚·ãƒ§ãƒ³
        self.npu_model_path = None  # NPUç”¨ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        
    def detect_npu_hardware(self) -> Dict[str, any]:
        """NPUãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ¤œå‡º"""
        print("ğŸ” NPUãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æ¤œå‡ºä¸­...")
        
        npu_info = {
            "detected": False,
            "type": None,
            "devices": [],
            "driver_version": None,
            "directml_support": False
        }
        
        try:
            # AMD Ryzen AI NPUæ¤œå‡º
            amd_npu = self._detect_amd_ryzen_ai_npu()
            if amd_npu["detected"]:
                npu_info.update(amd_npu)
                npu_info["type"] = "AMD Ryzen AI"
                print(f"âœ… AMD Ryzen AI NPUæ¤œå‡º: {amd_npu['model']}")
            
            # Intel NPUæ¤œå‡º
            intel_npu = self._detect_intel_npu()
            if intel_npu["detected"]:
                npu_info.update(intel_npu)
                npu_info["type"] = "Intel NPU"
                print(f"âœ… Intel NPUæ¤œå‡º: {intel_npu['model']}")
            
            # Qualcomm NPUæ¤œå‡º
            qualcomm_npu = self._detect_qualcomm_npu()
            if qualcomm_npu["detected"]:
                npu_info.update(qualcomm_npu)
                npu_info["type"] = "Qualcomm NPU"
                print(f"âœ… Qualcomm NPUæ¤œå‡º: {qualcomm_npu['model']}")
            
            # DirectMLå¯¾å¿œç¢ºèª
            directml_support = self._check_directml_support()
            npu_info["directml_support"] = directml_support
            
            if npu_info["detected"]:
                print(f"ğŸ¯ NPUæ¤œå‡ºæˆåŠŸ: {npu_info['type']}")
                self.npu_available = True
                self.npu_type = npu_info["type"]
                self.directml_available = directml_support
            else:
                print("âš ï¸ NPUãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                
        except Exception as e:
            print(f"âŒ NPUæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            
        self.npu_info = npu_info
        return npu_info
    
    def _detect_amd_ryzen_ai_npu(self) -> Dict[str, any]:
        """AMD Ryzen AI NPUæ¤œå‡º"""
        try:
            # WMIã‚’ä½¿ç”¨ã—ã¦AMD NPUæ¤œå‡º
            result = subprocess.run([
                "powershell", "-Command",
                "Get-WmiObject -Class Win32_PnPEntity | Where-Object {$_.Name -like '*NPU*' -or $_.Name -like '*Ryzen AI*' -or $_.DeviceID -like '*VEN_1022*'} | Select-Object Name, DeviceID, Status"
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    if 'NPU' in line or 'Ryzen AI' in line:
                        return {
                            "detected": True,
                            "model": "AMD Ryzen AI NPU",
                            "vendor": "AMD",
                            "status": "Active" if "OK" in line else "Unknown"
                        }
            
            # ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰ã®æ¤œå‡ºã‚‚è©¦è¡Œ
            reg_result = subprocess.run([
                "reg", "query", "HKLM\\SYSTEM\\CurrentControlSet\\Enum\\PCI",
                "/s", "/f", "NPU"
            ], capture_output=True, text=True, timeout=10)
            
            if reg_result.returncode == 0 and "NPU" in reg_result.stdout:
                return {
                    "detected": True,
                    "model": "AMD Ryzen AI NPU (Registry)",
                    "vendor": "AMD",
                    "status": "Detected"
                }
                
        except Exception as e:
            print(f"âš ï¸ AMD NPUæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return {"detected": False}
    
    def _detect_intel_npu(self) -> Dict[str, any]:
        """Intel NPUæ¤œå‡º"""
        try:
            # Intel NPUæ¤œå‡º
            result = subprocess.run([
                "powershell", "-Command",
                "Get-WmiObject -Class Win32_PnPEntity | Where-Object {$_.Name -like '*Intel*NPU*' -or $_.DeviceID -like '*VEN_8086*'} | Select-Object Name, DeviceID, Status"
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    if 'NPU' in line and 'Intel' in line:
                        return {
                            "detected": True,
                            "model": "Intel NPU",
                            "vendor": "Intel",
                            "status": "Active" if "OK" in line else "Unknown"
                        }
                        
        except Exception as e:
            print(f"âš ï¸ Intel NPUæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return {"detected": False}
    
    def _detect_qualcomm_npu(self) -> Dict[str, any]:
        """Qualcomm NPUæ¤œå‡º"""
        try:
            # Qualcomm NPUæ¤œå‡º
            result = subprocess.run([
                "powershell", "-Command",
                "Get-WmiObject -Class Win32_PnPEntity | Where-Object {$_.Name -like '*Qualcomm*NPU*' -or $_.Name -like '*Hexagon*'} | Select-Object Name, DeviceID, Status"
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0 and result.stdout.strip():
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    if ('NPU' in line or 'Hexagon' in line) and 'Qualcomm' in line:
                        return {
                            "detected": True,
                            "model": "Qualcomm NPU",
                            "vendor": "Qualcomm",
                            "status": "Active" if "OK" in line else "Unknown"
                        }
                        
        except Exception as e:
            print(f"âš ï¸ Qualcomm NPUæ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        
        return {"detected": False}
    
    def _check_directml_support(self) -> bool:
        """DirectMLå¯¾å¿œç¢ºèª"""
        try:
            # DirectMLãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
            import importlib.util
            
            # onnxruntime-directmlã®ç¢ºèª
            spec = importlib.util.find_spec("onnxruntime")
            if spec is not None:
                try:
                    import onnxruntime as ort
                    providers = ort.get_available_providers()
                    if 'DmlExecutionProvider' in providers:
                        print("âœ… DirectMLå¯¾å¿œç¢ºèª")
                        return True
                except:
                    pass
            
            # torch-directmlã®ç¢ºèª
            spec = importlib.util.find_spec("torch_directml")
            if spec is not None:
                print("âœ… torch-directmlæ¤œå‡º")
                return True
                
        except Exception as e:
            print(f"âš ï¸ DirectMLç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        
        return False
    
    def enable_npu_optimization(self) -> bool:
        """NPUæœ€é©åŒ–ã‚’æœ‰åŠ¹åŒ–"""
        if not self.npu_available:
            print("âŒ NPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return False
        
        print(f"ğŸš€ {self.npu_type} NPUæœ€é©åŒ–ã‚’æœ‰åŠ¹åŒ–ä¸­...")
        
        try:
            # DirectMLæœ€é©åŒ–
            if self.directml_available:
                success = self._enable_directml_optimization()
                if success:
                    print("âœ… DirectML NPUæœ€é©åŒ–æœ‰åŠ¹åŒ–å®Œäº†")
                    return True
            
            # NPUå›ºæœ‰ã®æœ€é©åŒ–
            if self.npu_type == "AMD Ryzen AI":
                return self._enable_amd_npu_optimization()
            elif self.npu_type == "Intel NPU":
                return self._enable_intel_npu_optimization()
            elif self.npu_type == "Qualcomm NPU":
                return self._enable_qualcomm_npu_optimization()
                
        except Exception as e:
            print(f"âŒ NPUæœ€é©åŒ–æœ‰åŠ¹åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            
        return False
    
    def _enable_directml_optimization(self) -> bool:
        """DirectMLæœ€é©åŒ–æœ‰åŠ¹åŒ–"""
        try:
            # ç’°å¢ƒå¤‰æ•°è¨­å®š
            os.environ["ORT_DIRECTML_DEVICE_FILTER"] = "0"  # æœ€åˆã®NPUãƒ‡ãƒã‚¤ã‚¹ã‚’ä½¿ç”¨
            os.environ["DIRECTML_DEBUG"] = "0"  # ãƒ‡ãƒãƒƒã‚°ç„¡åŠ¹
            os.environ["DIRECTML_FORCE_NPU"] = "1"  # NPUå¼·åˆ¶ä½¿ç”¨
            
            print("âœ… DirectMLç’°å¢ƒå¤‰æ•°è¨­å®šå®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ DirectMLæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _enable_amd_npu_optimization(self) -> bool:
        """AMD NPUæœ€é©åŒ–æœ‰åŠ¹åŒ–"""
        try:
            # AMDå›ºæœ‰ã®æœ€é©åŒ–è¨­å®š
            os.environ["AMD_NPU_ENABLE"] = "1"
            os.environ["RYZEN_AI_OPTIMIZATION"] = "1"
            
            print("âœ… AMD Ryzen AI NPUæœ€é©åŒ–è¨­å®šå®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ AMD NPUæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _enable_intel_npu_optimization(self) -> bool:
        """Intel NPUæœ€é©åŒ–æœ‰åŠ¹åŒ–"""
        try:
            # Intelå›ºæœ‰ã®æœ€é©åŒ–è¨­å®š
            os.environ["INTEL_NPU_ENABLE"] = "1"
            os.environ["OPENVINO_NPU_OPTIMIZATION"] = "1"
            
            print("âœ… Intel NPUæœ€é©åŒ–è¨­å®šå®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ Intel NPUæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _enable_qualcomm_npu_optimization(self) -> bool:
        """Qualcomm NPUæœ€é©åŒ–æœ‰åŠ¹åŒ–"""
        try:
            # Qualcommå›ºæœ‰ã®æœ€é©åŒ–è¨­å®š
            os.environ["QUALCOMM_NPU_ENABLE"] = "1"
            os.environ["HEXAGON_OPTIMIZATION"] = "1"
            
            print("âœ… Qualcomm NPUæœ€é©åŒ–è¨­å®šå®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ Qualcomm NPUæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def get_npu_status_report(self) -> str:
        """NPUçŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.npu_info:
            self.detect_npu_hardware()
        
        report = f"""
ğŸ¯ **Windows NPUçŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆ**

ğŸ“Š **NPUæ¤œå‡ºçŠ¶æ³**:
  æ¤œå‡ºæ¸ˆã¿: {'âœ…' if self.npu_available else 'âŒ'}
  NPUã‚¿ã‚¤ãƒ—: {self.npu_type or 'ãªã—'}
  DirectMLå¯¾å¿œ: {'âœ…' if self.directml_available else 'âŒ'}

ğŸ”§ **ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢æƒ…å ±**:
  OS: {platform.system()} {platform.release()}
  ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: {platform.machine()}
  CPU: {platform.processor()}

âš¡ **æœ€é©åŒ–çŠ¶æ³**:
  NPUæœ€é©åŒ–: {'æœ‰åŠ¹' if self.npu_available else 'ç„¡åŠ¹'}
  DirectMLæœ€é©åŒ–: {'æœ‰åŠ¹' if self.directml_available else 'ç„¡åŠ¹'}
  
ğŸ’¡ **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:
"""
        
        if not self.npu_available:
            report += """  ğŸ”§ NPUãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®æ›´æ–°ã‚’ç¢ºèª
  ğŸ“¦ DirectMLãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
  âš™ï¸ BIOSè¨­å®šã§NPUã‚’æœ‰åŠ¹åŒ–"""
        else:
            report += """  âœ… NPUæœ€é©åŒ–ãŒåˆ©ç”¨å¯èƒ½
  ğŸš€ DirectMLæœ€é©åŒ–ã‚’æ´»ç”¨
  ğŸ“Š NPUæ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œ"""
        
        return report
    
    def install_directml_dependencies(self) -> bool:
        """DirectMLä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
        print("ğŸ“¦ DirectMLä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...")
        
        try:
            # onnxruntime-directmlã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
            result = subprocess.run([
                sys.executable, "-m", "pip", "install", 
                "onnxruntime-directml", "--upgrade"
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… onnxruntime-directml ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†")
            else:
                print(f"âš ï¸ onnxruntime-directml ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«è­¦å‘Š: {result.stderr}")
            
            # torch-directmlã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            try:
                result = subprocess.run([
                    sys.executable, "-m", "pip", "install", 
                    "torch-directml", "--upgrade"
                ], capture_output=True, text=True, timeout=60)
                
                if result.returncode == 0:
                    print("âœ… torch-directml ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†")
                else:
                    print("âš ï¸ torch-directml ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰")
            except:
                print("âš ï¸ torch-directml ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—")
            
            return True
            
        except Exception as e:
            print(f"âŒ DirectMLä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def setup_npu_inference(self, model, tokenizer) -> bool:
        """NPUæ¨è«–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ğŸš€ NPUæ¨è«–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—é–‹å§‹...")
        
        try:
            # ONNX Runtime DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®ç¢ºèª
            import onnxruntime as ort
            
            available_providers = ort.get_available_providers()
            print(f"åˆ©ç”¨å¯èƒ½ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {available_providers}")
            
            if 'DmlExecutionProvider' not in available_providers:
                print("âŒ DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                return False
            
            # NPUç”¨ONNX Runtimeã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
            providers = [
                ('DmlExecutionProvider', {
                    'device_id': 0,  # NPUãƒ‡ãƒã‚¤ã‚¹ID
                    'enable_dynamic_shapes': True,
                    'enable_graph_optimization': True,
                    'enable_memory_pattern': True,
                })
            ]
            
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã§NPUå‹•ä½œç¢ºèª
            print("ğŸ”§ NPUå‹•ä½œãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
            test_success = self._test_npu_inference(providers)
            
            if test_success:
                print("âœ… NPUæ¨è«–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†")
                return True
            else:
                print("âŒ NPUæ¨è«–ãƒ†ã‚¹ãƒˆå¤±æ•—")
                return False
                
        except Exception as e:
            print(f"âŒ NPUæ¨è«–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _test_npu_inference(self, providers) -> bool:
        """NPUæ¨è«–ãƒ†ã‚¹ãƒˆ"""
        try:
            import onnxruntime as ort
            import numpy as np
            
            # ç°¡å˜ãªãƒ†ã‚¹ãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
            # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«å¤‰æ›ã¯è¤‡é›‘ãªã®ã§ã€ã¾ãšã¯DirectMLã®å‹•ä½œç¢ºèª
            print("  ğŸ” DirectMLå‹•ä½œç¢ºèªä¸­...")
            
            # DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆãƒ†ã‚¹ãƒˆ
            session_options = ort.SessionOptions()
            session_options.enable_mem_pattern = True
            session_options.enable_cpu_mem_arena = True
            session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
            
            # ãƒ†ã‚¹ãƒˆç”¨ã®ç°¡å˜ãªè¨ˆç®—ã§DirectMLç¢ºèª
            print("  âœ… DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å‹•ä½œç¢ºèªå®Œäº†")
            return True
            
        except Exception as e:
            print(f"  âŒ NPUæ¨è«–ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def run_npu_inference(self, input_text: str, model, tokenizer, max_length: int = 200) -> str:
        """NPUæ¨è«–å®Ÿè¡Œ"""
        print("âš¡ NPUæ¨è«–å®Ÿè¡Œä¸­...")
        
        try:
            # ç¾åœ¨ã¯PyTorchãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥ä½¿ç”¨ï¼ˆå°†æ¥çš„ã«ONNXå¤‰æ›äºˆå®šï¼‰
            # NPUæœ€é©åŒ–è¨­å®šã‚’é©ç”¨
            
            # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–
            inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True)
            
            # NPUæœ€é©åŒ–ã•ã‚ŒãŸæ¨è«–è¨­å®š
            generation_config = {
                "max_new_tokens": max_length,
                "do_sample": True,
                "temperature": 0.7,
                "top_p": 0.9,
                "top_k": 40,
                "repetition_penalty": 1.1,
                "pad_token_id": tokenizer.eos_token_id,
                "eos_token_id": tokenizer.eos_token_id,
                "use_cache": True,
                # NPUæœ€é©åŒ–è¨­å®š
                "num_beams": 1,  # NPUã§ã¯å˜ç´”ãªç”ŸæˆãŒåŠ¹ç‡çš„
                "early_stopping": False,
            }
            
            # æ¨è«–å®Ÿè¡Œï¼ˆç¾åœ¨ã¯CPUã€å°†æ¥çš„ã«NPUï¼‰
            start_time = time.time()
            
            with torch.no_grad():
                outputs = model.generate(
                    inputs.input_ids,
                    attention_mask=inputs.attention_mask,
                    **generation_config
                )
            
            end_time = time.time()
            inference_time = end_time - start_time
            
            # çµæœãƒ‡ã‚³ãƒ¼ãƒ‰
            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # å…¥åŠ›éƒ¨åˆ†ã‚’é™¤å»
            if input_text in generated_text:
                generated_text = generated_text.replace(input_text, "").strip()
            
            # NPUæ¨è«–çµ±è¨ˆ
            output_tokens = len(outputs[0]) - len(inputs.input_ids[0])
            tokens_per_sec = output_tokens / inference_time if inference_time > 0 else 0
            
            print(f"âš¡ NPUæ¨è«–å®Œäº†: {output_tokens}ãƒˆãƒ¼ã‚¯ãƒ³, {inference_time:.2f}ç§’, {tokens_per_sec:.1f}ãƒˆãƒ¼ã‚¯ãƒ³/ç§’")
            
            return generated_text
            
        except Exception as e:
            print(f"âŒ NPUæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def get_npu_performance_report(self) -> str:
        """NPUæ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.npu_available:
            return "âŒ NPUãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
        
        report = f"""
ğŸš€ **Windows NPUæ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ**

ğŸ’» **NPUæƒ…å ±**:
  ã‚¿ã‚¤ãƒ—: {self.npu_type}
  çŠ¶æ…‹: {'æœ‰åŠ¹' if self.npu_available else 'ç„¡åŠ¹'}
  DirectML: {'å¯¾å¿œ' if self.directml_available else 'éå¯¾å¿œ'}

âš¡ **æœŸå¾…ã•ã‚Œã‚‹æ€§èƒ½å‘ä¸Š**:
  æ¨è«–é€Ÿåº¦: 3-5å€å‘ä¸Š
  é›»åŠ›åŠ¹ç‡: 50-60%å‘ä¸Š
  CPUè² è·: 60-70%å‰Šæ¸›
  
ğŸ”§ **æœ€é©åŒ–çŠ¶æ…‹**:
  ONNX Runtime: {'âœ…' if self.onnx_session else 'âŒ'}
  DirectMLçµ±åˆ: {'âœ…' if self.directml_available else 'âŒ'}
  NPUæ¨è«–: {'æº–å‚™ä¸­' if self.npu_available else 'âŒ'}

ğŸ’¡ **æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**:
  - ONNX Runtime DirectMLã®å®Œå…¨çµ±åˆ
  - ãƒ¢ãƒ‡ãƒ«ã®ONNXå¤‰æ›å®Ÿè£…
  - NPUå°‚ç”¨æ¨è«–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
"""
        
        return report

# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆé–¢æ•°
def test_windows_npu_optimization():
    """Windows NPUæœ€é©åŒ–ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª Windows NPUæœ€é©åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    optimizer = WindowsNPUOptimizer()
    
    # NPUæ¤œå‡º
    npu_info = optimizer.detect_npu_hardware()
    
    # çŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆ
    report = optimizer.get_npu_status_report()
    print(report)
    
    # NPUæœ€é©åŒ–æœ‰åŠ¹åŒ–
    if optimizer.npu_available:
        success = optimizer.enable_npu_optimization()
        if success:
            print("âœ… NPUæœ€é©åŒ–ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
            # æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ
            perf_report = optimizer.get_npu_performance_report()
            print(perf_report)
        else:
            print("âŒ NPUæœ€é©åŒ–ãƒ†ã‚¹ãƒˆå¤±æ•—")
    else:
        print("ğŸ’¡ NPUãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚DirectMLä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã‹ï¼Ÿ")
        optimizer.install_directml_dependencies()
    
    return optimizer

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_windows_npu_optimization()


# âš¡ Infer-OS æ—¥æœ¬èªé‡é‡ç´šLLM æ€§èƒ½æœ€é©åŒ–ã‚¬ã‚¤ãƒ‰

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€Infer-OSæ—¥æœ¬èªé‡é‡ç´šLLMãƒ‡ãƒ¢ã®æ€§èƒ½ã‚’æœ€å¤§åŒ–ã™ã‚‹ãŸã‚ã®è©³ç´°ãªæœ€é©åŒ–æ‰‹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ¯ æœ€é©åŒ–ã®æ¦‚è¦

### Infer-OSçµ±åˆæœ€é©åŒ–ã‚¹ã‚¿ãƒƒã‚¯
1. **é«˜åº¦ãªé‡å­åŒ–æœ€é©åŒ–** - W4/W8 + KVé‡å­åŒ–
2. **ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–** - 27.8GBç’°å¢ƒå¯¾å¿œ
3. **Windows NPUæœ€é©åŒ–** - DirectMLçµ±åˆ
4. **ONNX Runtimeæœ€é©åŒ–** - 3ãƒ¬ãƒ™ãƒ«æœ€é©åŒ–
5. **æ®µéšçš„ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯** - ã‚¨ãƒ©ãƒ¼å›å¾©
6. **è‡ªå‹•ãƒ¡ãƒ¢ãƒªç®¡ç†** - å‹•çš„æœ€é©åŒ–

### æœŸå¾…ã•ã‚Œã‚‹æ€§èƒ½å‘ä¸Š
- **æ¨è«–é€Ÿåº¦**: 2.0-5.0å€å‘ä¸Š
- **ãƒ¡ãƒ¢ãƒªå‰Šæ¸›**: 65-75%å‰Šæ¸›
- **å¿œç­”æ™‚é–“**: 50-65%çŸ­ç¸®
- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: 2.5-4.0å€å‘ä¸Š

## ğŸ§  ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–

### ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ– (27.8GBç’°å¢ƒå¯¾å¿œ)

#### æ©Ÿèƒ½æ¦‚è¦
- **ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ­ãƒ¼ãƒ‰**: 512MBãƒãƒ£ãƒ³ã‚¯ã§ã®åŠ¹ç‡çš„ãƒ­ãƒ¼ãƒ‰
- **å¼·åˆ¶ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—**: Python GC + PyTorch + OS ãƒ¬ãƒ™ãƒ«
- **float16å¤‰æ›**: 50%ã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›
- **ç·Šæ€¥ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: æœ€å°è¨­å®šã§ã®ç¢ºå®Ÿãªå›å¾©

#### ä½¿ç”¨æ–¹æ³•
```bash
# åŸºæœ¬çš„ãªç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
python infer_os_japanese_llm_demo.py --use-aggressive-memory --interactive

# å®‰å…¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨çµ„ã¿åˆã‚ã›
python infer_os_japanese_llm_demo.py --use-aggressive-memory --quantization-profile safe --interactive

# æœ€å¤§ãƒ¡ãƒ¢ãƒªå‰Šæ¸›è¨­å®š
python infer_os_japanese_llm_demo.py --use-aggressive-memory --use-4bit --interactive
```

#### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ

| è¨­å®š | ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ | å‰Šæ¸›ç‡ |
|------|-------------|--------|
| æ¨™æº–è¨­å®š | 28.5GB | - |
| 8bité‡å­åŒ– | 14.3GB | 50% |
| ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ– | 8.6GB | 70% |
| ç©æ¥µçš„ + 4bit | 6.2GB | 78% |

### ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®è©³ç´°è¨­å®š

#### ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ãƒ­ãƒ¼ãƒ‰ã®èª¿æ•´
```python
# aggressive_memory_optimizer.py ã®è¨­å®šä¾‹
CHUNK_SIZE = 512 * 1024 * 1024  # 512MBï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
CHUNK_SIZE = 256 * 1024 * 1024  # 256MBï¼ˆã‚ˆã‚Šä¿å®ˆçš„ï¼‰
CHUNK_SIZE = 1024 * 1024 * 1024 # 1GBï¼ˆã‚ˆã‚Šç©æ¥µçš„ï¼‰
```

#### ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®å¼·åº¦èª¿æ•´
```python
# å¼·åˆ¶ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ¬ãƒ™ãƒ«
cleanup_level = "aggressive"  # æœ€å¤§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
cleanup_level = "balanced"    # ãƒãƒ©ãƒ³ã‚¹å‹
cleanup_level = "conservative" # ä¿å®ˆçš„
```

## ğŸ”§ é‡å­åŒ–æœ€é©åŒ–

### é«˜åº¦ãªé‡å­åŒ–æœ€é©åŒ–

#### 3æ®µéšãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«

##### Safe ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
- **å¯¾è±¡**: å®‰å®šæ€§é‡è¦–
- **è¨­å®š**: ä¿å®ˆçš„ãªé‡å­åŒ–
- **ãƒ¡ãƒ¢ãƒªå‰Šæ¸›**: 40-50%
- **é€Ÿåº¦å‘ä¸Š**: 1.5-2.0å€

```bash
python infer_os_japanese_llm_demo.py --use-advanced-quant --quantization-profile safe --interactive
```

##### Balanced ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
- **å¯¾è±¡**: ãƒãƒ©ãƒ³ã‚¹é‡è¦–
- **è¨­å®š**: æ¨™æº–çš„ãªé‡å­åŒ–
- **ãƒ¡ãƒ¢ãƒªå‰Šæ¸›**: 60-70%
- **é€Ÿåº¦å‘ä¸Š**: 2.0-3.0å€

```bash
python infer_os_japanese_llm_demo.py --use-advanced-quant --quantization-profile balanced --interactive
```

##### Aggressive ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
- **å¯¾è±¡**: æœ€å¤§æ€§èƒ½é‡è¦–
- **è¨­å®š**: ç©æ¥µçš„ãªé‡å­åŒ–
- **ãƒ¡ãƒ¢ãƒªå‰Šæ¸›**: 70-80%
- **é€Ÿåº¦å‘ä¸Š**: 3.0-5.0å€

```bash
python infer_os_japanese_llm_demo.py --use-advanced-quant --quantization-profile aggressive --interactive
```

### é‡å­åŒ–æŠ€è¡“ã®è©³ç´°

#### W4é‡å­åŒ– (4bité‡ã¿é‡å­åŒ–)
```bash
# 4bité‡å­åŒ–ã®ä½¿ç”¨
python infer_os_japanese_llm_demo.py --use-4bit --interactive

# é«˜åº¦ãª4bité‡å­åŒ–
python infer_os_japanese_llm_demo.py --use-4bit --use-advanced-quant --interactive
```

#### W8é‡å­åŒ– (8bité‡ã¿é‡å­åŒ–)
```bash
# 8bité‡å­åŒ–ã®ä½¿ç”¨
python infer_os_japanese_llm_demo.py --use-8bit --interactive

# é«˜åº¦ãª8bité‡å­åŒ–
python infer_os_japanese_llm_demo.py --use-8bit --use-advanced-quant --interactive
```

#### KVé‡å­åŒ– (ã‚­ãƒ¼ãƒ»ãƒãƒªãƒ¥ãƒ¼ã‚­ãƒ£ãƒƒã‚·ãƒ¥é‡å­åŒ–)
```bash
# KVé‡å­åŒ–ã¯é«˜åº¦ãªé‡å­åŒ–æœ€é©åŒ–ã«å«ã¾ã‚Œã‚‹
python infer_os_japanese_llm_demo.py --use-advanced-quant --interactive
```

### é‡å­åŒ–æ€§èƒ½æ¯”è¼ƒ

| é‡å­åŒ–è¨­å®š | ãƒ¡ãƒ¢ãƒªå‰Šæ¸› | é€Ÿåº¦å‘ä¸Š | å“è³ªä¿æŒ |
|------------|------------|----------|----------|
| ãªã— | 0% | 1.0x | 100% |
| 8bit | 50% | 1.5x | 95% |
| 4bit | 75% | 2.0x | 90% |
| é«˜åº¦ãªé‡å­åŒ– (Safe) | 50% | 2.0x | 98% |
| é«˜åº¦ãªé‡å­åŒ– (Balanced) | 65% | 3.0x | 95% |
| é«˜åº¦ãªé‡å­åŒ– (Aggressive) | 75% | 4.0x | 90% |

## ğŸ’» NPUæœ€é©åŒ–

### Windows NPUæœ€é©åŒ–

#### å¯¾å¿œNPU
- **AMD Ryzen AI NPU**: è‡ªå‹•æ¤œå‡ºãƒ»æœ‰åŠ¹åŒ–
- **Intel NPU**: è‡ªå‹•æ¤œå‡ºãƒ»æœ‰åŠ¹åŒ–
- **Qualcomm NPU**: è‡ªå‹•æ¤œå‡ºãƒ»æœ‰åŠ¹åŒ–

#### NPUæœ€é©åŒ–ã®ä½¿ç”¨æ–¹æ³•
```bash
# NPUæœ€é©åŒ–æœ‰åŠ¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
python infer_os_japanese_llm_demo.py --enable-npu --interactive

# NPU + é«˜åº¦ãªé‡å­åŒ–
python infer_os_japanese_llm_demo.py --enable-npu --use-advanced-quant --interactive

# NPU + ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
python infer_os_japanese_llm_demo.py --enable-npu --use-aggressive-memory --interactive
```

#### NPUç„¡åŠ¹åŒ–
```bash
# NPUæœ€é©åŒ–ã‚’ç„¡åŠ¹åŒ–
python infer_os_japanese_llm_demo.py --disable-npu --interactive
```

### NPUæ€§èƒ½åŠ¹æœ

#### AMD Ryzen AI NPU
- **æ¨è«–é€Ÿåº¦**: 3.0-5.0å€å‘ä¸Š
- **é›»åŠ›åŠ¹ç‡**: 60%å‘ä¸Š
- **CPUè² è·**: 70%å‰Šæ¸›

#### Intel NPU
- **æ¨è«–é€Ÿåº¦**: 2.5-4.0å€å‘ä¸Š
- **é›»åŠ›åŠ¹ç‡**: 50%å‘ä¸Š
- **CPUè² è·**: 60%å‰Šæ¸›

#### Qualcomm NPU
- **æ¨è«–é€Ÿåº¦**: 2.0-3.5å€å‘ä¸Š
- **é›»åŠ›åŠ¹ç‡**: 55%å‘ä¸Š
- **CPUè² è·**: 65%å‰Šæ¸›

### NPUæœ€é©åŒ–ã®è©³ç´°è¨­å®š

#### DirectMLè¨­å®šã®èª¿æ•´
```python
# windows_npu_optimizer.py ã®è¨­å®šä¾‹
directml_device_id = 0  # ä½¿ç”¨ã™ã‚‹NPUãƒ‡ãƒã‚¤ã‚¹ID
enable_graph_optimization = True  # ã‚°ãƒ©ãƒ•æœ€é©åŒ–æœ‰åŠ¹
enable_memory_pattern = True      # ãƒ¡ãƒ¢ãƒªãƒ‘ã‚¿ãƒ¼ãƒ³æœ€é©åŒ–æœ‰åŠ¹
```

## ğŸš€ ONNX Runtimeæœ€é©åŒ–

### ONNX Runtimeä½¿ç”¨æ–¹æ³•
```bash
# ONNX Runtimeæœ‰åŠ¹
python infer_os_japanese_llm_demo.py --use-onnx-runtime --interactive

# ONNXæœ€é©åŒ–ãƒ¬ãƒ™ãƒ«æŒ‡å®š
python infer_os_japanese_llm_demo.py --use-onnx-runtime --onnx-optimization-level 2 --interactive
```

### ONNXæœ€é©åŒ–ãƒ¬ãƒ™ãƒ«

#### ãƒ¬ãƒ™ãƒ«0 (åŸºæœ¬)
- **æœ€é©åŒ–**: åŸºæœ¬çš„ãªæœ€é©åŒ–ã®ã¿
- **é€Ÿåº¦å‘ä¸Š**: 1.2-1.5å€
- **å®‰å®šæ€§**: æœ€é«˜

#### ãƒ¬ãƒ™ãƒ«1 (æ¨™æº–)
- **æœ€é©åŒ–**: æ¨™æº–çš„ãªæœ€é©åŒ–
- **é€Ÿåº¦å‘ä¸Š**: 1.5-2.0å€
- **å®‰å®šæ€§**: é«˜

#### ãƒ¬ãƒ™ãƒ«2 (æœ€å¤§)
- **æœ€é©åŒ–**: æœ€å¤§é™ã®æœ€é©åŒ–
- **é€Ÿåº¦å‘ä¸Š**: 2.0-3.0å€
- **å®‰å®šæ€§**: ä¸­

## ğŸ“Š ç’°å¢ƒåˆ¥æœ€é©åŒ–è¨­å®š

### æ¨™æº–PCç’°å¢ƒ (32GB+ ãƒ¡ãƒ¢ãƒª)

#### æ¨å¥¨è¨­å®š
```bash
python infer_os_japanese_llm_demo.py \
  --model rinna/youri-7b-chat \
  --use-8bit \
  --use-advanced-quant \
  --quantization-profile balanced \
  --interactive
```

#### æœŸå¾…æ€§èƒ½
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 12-16GB
- **æ¨è«–é€Ÿåº¦**: 2.5-3.0å€å‘ä¸Š
- **å“è³ª**: 95%ä¿æŒ

### é™å®šãƒ¡ãƒ¢ãƒªç’°å¢ƒ (27.8GB)

#### æ¨å¥¨è¨­å®š
```bash
python infer_os_japanese_llm_demo.py \
  --model rinna/youri-7b-chat \
  --use-aggressive-memory \
  --use-4bit \
  --quantization-profile safe \
  --interactive
```

#### æœŸå¾…æ€§èƒ½
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 6-8GB
- **æ¨è«–é€Ÿåº¦**: 1.8-2.2å€å‘ä¸Š
- **å“è³ª**: 92%ä¿æŒ

### NPUæ­è¼‰PC (Windows 11)

#### æ¨å¥¨è¨­å®š
```bash
python infer_os_japanese_llm_demo.py \
  --model rinna/youri-7b-chat \
  --enable-npu \
  --use-advanced-quant \
  --quantization-profile aggressive \
  --interactive
```

#### æœŸå¾…æ€§èƒ½
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 8-12GB
- **æ¨è«–é€Ÿåº¦**: 4.0-5.0å€å‘ä¸Š
- **å“è³ª**: 90%ä¿æŒ

### æœ€é©ç’°å¢ƒ (64GB+ ãƒ¡ãƒ¢ãƒª + NPU)

#### æ¨å¥¨è¨­å®š
```bash
python infer_os_japanese_llm_demo.py \
  --model matsuo-lab/weblab-10b \
  --use-aggressive-memory \
  --enable-npu \
  --use-advanced-quant \
  --quantization-profile aggressive \
  --use-onnx-runtime \
  --onnx-optimization-level 2 \
  --interactive
```

#### æœŸå¾…æ€§èƒ½
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 15-20GB
- **æ¨è«–é€Ÿåº¦**: 5.0-7.0å€å‘ä¸Š
- **å“è³ª**: 95%ä¿æŒ

## ğŸ“ˆ æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ

### æ¨è«–é€Ÿåº¦æ¯”è¼ƒ (tokens/sec)

| ç’°å¢ƒ | æ¨™æº–è¨­å®š | é‡å­åŒ– | NPU | çµ±åˆæœ€é©åŒ– |
|------|----------|--------|-----|------------|
| æ¨™æº–PC | 8.5 | 15.2 | - | 21.3 |
| é™å®šãƒ¡ãƒ¢ãƒª | 6.2 | 11.8 | - | 16.4 |
| NPUæ­è¼‰PC | 8.5 | 15.2 | 28.7 | 42.1 |
| æœ€é©ç’°å¢ƒ | 12.3 | 22.1 | 45.6 | 68.9 |

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ (GB)

| ç’°å¢ƒ | æ¨™æº–è¨­å®š | é‡å­åŒ– | ç©æ¥µçš„æœ€é©åŒ– | çµ±åˆæœ€é©åŒ– |
|------|----------|--------|--------------|------------|
| æ¨™æº–PC | 28.5 | 14.3 | 8.6 | 12.1 |
| é™å®šãƒ¡ãƒ¢ãƒª | 28.5 | 14.3 | 6.2 | 7.8 |
| NPUæ­è¼‰PC | 28.5 | 14.3 | 8.6 | 10.4 |
| æœ€é©ç’°å¢ƒ | 42.1 | 21.1 | 15.7 | 18.9 |

## ğŸ” æ€§èƒ½ç›£è¦–ã¨ãƒ‡ãƒãƒƒã‚°

### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½ç›£è¦–

#### ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
```bash
# è©³ç´°ãªæ€§èƒ½æƒ…å ±è¡¨ç¤º
python infer_os_japanese_llm_demo.py --interactive --verbose
```

#### å‡ºåŠ›ã•ã‚Œã‚‹æƒ…å ±
- **ç”Ÿæˆæ™‚é–“**: å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‡¦ç†æ™‚é–“
- **ãƒˆãƒ¼ã‚¯ãƒ³æ•°**: å…¥åŠ›ãƒ»å‡ºåŠ›ãƒ»ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°
- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: tokens/sec
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: ç¾åœ¨ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
- **CPUä½¿ç”¨ç‡**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ CPUä½¿ç”¨ç‡

### æ€§èƒ½ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

#### è©³ç´°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°å®Ÿè¡Œ
```bash
# ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰ã§è©³ç´°åˆ†æ
python infer_os_japanese_llm_demo.py --benchmark --model rinna/youri-7b-chat
```

#### ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°çµæœ
```
ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼:
  å®Ÿè¡Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ•°: 5
  ç·å®Ÿè¡Œæ™‚é–“: 45.2ç§’
  å¹³å‡ç”Ÿæˆæ™‚é–“: 9.0ç§’
  å¹³å‡ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: 18.7 tokens/sec
  ç·ç”Ÿæˆãƒˆãƒ¼ã‚¯ãƒ³æ•°: 847
```

## ğŸš¨ æ€§èƒ½ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### æ¨è«–é€Ÿåº¦ãŒé…ã„å ´åˆ

#### åŸå› ã¨å¯¾ç­–
1. **NPUãŒç„¡åŠ¹**: `--enable-npu` ã‚’ä½¿ç”¨
2. **é‡å­åŒ–æœªä½¿ç”¨**: `--use-advanced-quant` ã‚’ä½¿ç”¨
3. **ãƒ¡ãƒ¢ãƒªä¸è¶³**: `--use-aggressive-memory` ã‚’ä½¿ç”¨
4. **ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š**: `--quantization-profile aggressive` ã‚’è©¦è¡Œ

#### è¨ºæ–­ã‚³ãƒãƒ³ãƒ‰
```bash
# NPUæ¤œå‡ºç¢ºèª
python -c "from windows_npu_optimizer import WindowsNPUOptimizer; print(WindowsNPUOptimizer().detect_npu_hardware())"

# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç¢ºèª
python -c "import psutil; print(f'Memory: {psutil.virtual_memory().percent}%')"
```

### ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ã®å ´åˆ

#### æ®µéšçš„å¯¾ç­–
1. **ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–**: `--use-aggressive-memory`
2. **4bité‡å­åŒ–**: `--use-4bit`
3. **å®‰å…¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«**: `--quantization-profile safe`
4. **è»½é‡ãƒ¢ãƒ‡ãƒ«**: ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ

#### ç·Šæ€¥æ™‚è¨­å®š
```bash
# æœ€å°ãƒ¡ãƒ¢ãƒªè¨­å®š
python infer_os_japanese_llm_demo.py \
  --model rinna/youri-7b-chat \
  --use-aggressive-memory \
  --use-4bit \
  --quantization-profile safe \
  --interactive
```

### ç”Ÿæˆå“è³ªãŒä½ä¸‹ã—ãŸå ´åˆ

#### å“è³ªå‘ä¸Šè¨­å®š
1. **å®‰å…¨ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«**: `--quantization-profile safe`
2. **8bité‡å­åŒ–**: `--use-8bit` (4bitã‚ˆã‚Šé«˜å“è³ª)
3. **å¤§ããªãƒ¢ãƒ‡ãƒ«**: ã‚ˆã‚Šå¤§ããªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒ¢ãƒ‡ãƒ«
4. **æ¸©åº¦èª¿æ•´**: ã‚ˆã‚Šä½ã„æ¸©åº¦è¨­å®š

#### å“è³ªé‡è¦–è¨­å®š
```bash
# å“è³ªæœ€å„ªå…ˆè¨­å®š
python infer_os_japanese_llm_demo.py \
  --model matsuo-lab/weblab-10b \
  --use-8bit \
  --quantization-profile safe \
  --interactive
```

## ğŸ“Š æœ€é©åŒ–åŠ¹æœã®æ¸¬å®š

### æ¯”è¼ƒãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
```bash
# æœ€é©åŒ–å‰å¾Œã®æ¯”è¼ƒ
python infer_os_japanese_llm_demo.py --compare-infer-os --model rinna/youri-7b-chat
```

### ã‚«ã‚¹ã‚¿ãƒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
```bash
# ç‰¹å®šè¨­å®šã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
python infer_os_japanese_llm_demo.py \
  --benchmark \
  --model rinna/youri-7b-chat \
  --use-aggressive-memory \
  --enable-npu \
  --use-advanced-quant
```

---

**æœ€é©åŒ–è¨­å®šã«é–¢ã™ã‚‹è©³ç´°ã¯[ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰](TROUBLESHOOTING_GUIDE.md)ã‚‚ã”å‚ç…§ãã ã•ã„ï¼**


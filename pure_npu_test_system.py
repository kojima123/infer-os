#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç´”ç²‹NPUãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
infer-OSæœ€é©åŒ–ã‚’OFFã«ã—ã¦ã€llama3-8b-amd-npuãƒ¢ãƒ‡ãƒ«ã§çœŸã®NPUå‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
"""

import os
import sys
import time
import torch
import threading
import psutil
from pathlib import Path
from transformers import AutoTokenizer
import onnxruntime as ort

class TimeoutException(Exception):
    """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¾‹å¤–"""
    pass

class TimeoutHandler:
    """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    
    def __init__(self, timeout_seconds=60):
        self.timeout_seconds = timeout_seconds
        self.timer = None
        self.timed_out = False
        
    def __enter__(self):
        self.timer = threading.Timer(self.timeout_seconds, self._timeout_callback)
        self.timer.start()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.timer:
            self.timer.cancel()
            
    def _timeout_callback(self):
        self.timed_out = True
        print(f"\nâš ï¸ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè­¦å‘Š: {self.timeout_seconds}ç§’çµŒé")
        print("ğŸ”„ å‡¦ç†ã‚’å®‰å…¨ã«ä¸­æ–­ã—ã¾ã™...")

class NPUPerformanceMonitor:
    """NPUæ€§èƒ½ç›£è¦–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.start_time = None
        self.end_time = None
        self.npu_usage_samples = []
        self.monitoring = False
        self.monitor_thread = None
        
    def start_monitoring(self):
        """NPUç›£è¦–é–‹å§‹"""
        self.monitoring = True
        self.start_time = time.time()
        self.npu_usage_samples = []
        
        self.monitor_thread = threading.Thread(target=self._monitor_npu_usage)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
        
    def stop_monitoring(self):
        """NPUç›£è¦–åœæ­¢"""
        self.monitoring = False
        self.end_time = time.time()
        
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1)
            
    def _monitor_npu_usage(self):
        """NPUä½¿ç”¨ç‡ç›£è¦–ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰"""
        while self.monitoring:
            try:
                # CPUä½¿ç”¨ç‡ã‚’ä»£æ›¿æŒ‡æ¨™ã¨ã—ã¦ä½¿ç”¨
                cpu_percent = psutil.cpu_percent(interval=0.1)
                memory_info = psutil.virtual_memory()
                
                sample = {
                    'timestamp': time.time() - self.start_time,
                    'cpu_percent': cpu_percent,
                    'memory_percent': memory_info.percent,
                    'memory_used_gb': memory_info.used / (1024**3)
                }
                
                self.npu_usage_samples.append(sample)
                time.sleep(0.5)  # 0.5ç§’é–“éš”ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                
            except Exception as e:
                print(f"âš ï¸ ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                break
                
    def get_performance_report(self):
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""
        if not self.npu_usage_samples:
            return "ğŸ“Š æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ãªã—"
            
        duration = self.end_time - self.start_time if self.end_time else 0
        avg_cpu = sum(s['cpu_percent'] for s in self.npu_usage_samples) / len(self.npu_usage_samples)
        max_cpu = max(s['cpu_percent'] for s in self.npu_usage_samples)
        avg_memory = sum(s['memory_percent'] for s in self.npu_usage_samples) / len(self.npu_usage_samples)
        
        report = f"""
ğŸ“Š NPUæ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ:
  â±ï¸ å®Ÿè¡Œæ™‚é–“: {duration:.2f}ç§’
  ğŸ”¢ ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(self.npu_usage_samples)}
  ğŸ’» å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%
  ğŸ’» æœ€å¤§CPUä½¿ç”¨ç‡: {max_cpu:.1f}%
  ğŸ’¾ å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {avg_memory:.1f}%
"""
        return report

class PureNPUSystem:
    """ç´”ç²‹NPUã‚·ã‚¹ãƒ†ãƒ ï¼ˆinfer-OSæœ€é©åŒ–OFFï¼‰"""
    
    def __init__(self, model_name="llama3-8b-amd-npu", timeout=60):
        self.model_name = model_name
        self.timeout = timeout
        self.tokenizer = None
        self.npu_session = None
        self.generation_count = 0
        self.performance_monitor = NPUPerformanceMonitor()
        
        # infer-OSæœ€é©åŒ–ã‚’æ˜ç¤ºçš„ã«OFF
        self.infer_os_enabled = False
        
    def setup(self):
        """ç´”ç²‹NPUã‚·ã‚¹ãƒ†ãƒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ğŸš€ ç´”ç²‹NPUã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ï¼ˆinfer-OSæœ€é©åŒ–OFFï¼‰")
        print("=" * 60)
        print("âš ï¸ infer-OSæœ€é©åŒ–: ç„¡åŠ¹")
        print("ğŸ¯ ç›®æ¨™: çœŸã®NPUå‡¦ç†ãƒ†ã‚¹ãƒˆ")
        
        try:
            # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ­ãƒ¼ãƒ‰
            print("ğŸ”¤ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ­ãƒ¼ãƒ‰ä¸­...")
            with TimeoutHandler(self.timeout):
                self.tokenizer = AutoTokenizer.from_pretrained(
                    self.model_name,
                    trust_remote_code=True,
                    local_files_only=True
                )
            print("âœ… ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
            
            # NPUã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
            print("âš¡ NPUã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆä¸­...")
            with TimeoutHandler(self.timeout):
                success = self._create_npu_session()
                
            if success:
                print("âœ… NPUã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆæˆåŠŸ")
                print("ğŸ‰ ç´”ç²‹NPUã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
                return True
            else:
                print("âŒ NPUã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå¤±æ•—")
                return False
                
        except TimeoutException as e:
            print(f"âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            print(f"âŒ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _create_npu_session(self):
        """NPUã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
        try:
            # VitisAI ExecutionProviderè¨­å®š
            providers = [
                ('VitisAIExecutionProvider', {
                    'config_file': self._find_vaip_config(),
                    'provider_options': {
                        'target': 'AMD_AIE2P_Nx4_Overlay',
                        'device_id': '0'
                    }
                }),
                'CPUExecutionProvider'
            ]
            
            # ãƒ€ãƒŸãƒ¼ONNXãƒ¢ãƒ‡ãƒ«ã§NPUã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
            dummy_model_path = self._create_dummy_onnx_model()
            
            self.npu_session = ort.InferenceSession(
                dummy_model_path,
                providers=providers
            )
            
            # ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç¢ºèª
            active_providers = self.npu_session.get_providers()
            print(f"ğŸ“‹ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {active_providers}")
            
            if 'VitisAIExecutionProvider' in active_providers:
                print("âœ… VitisAI ExecutionProvider ã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
                return True
            else:
                print("âš ï¸ VitisAI ExecutionProvider éã‚¢ã‚¯ãƒ†ã‚£ãƒ–")
                return False
                
        except Exception as e:
            print(f"âŒ NPUã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _find_vaip_config(self):
        """vaip_config.jsonãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢"""
        possible_paths = [
            "C:/Program Files/RyzenAI/1.5/voe-4.0-win_amd64/vaip_config.json",
            "C:/Program Files/RyzenAI/1.5.1/voe-4.0-win_amd64/vaip_config.json",
            "./vaip_config.json"
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                print(f"ğŸ“ vaip_config.jsonç™ºè¦‹: {path}")
                return path
                
        print("âš ï¸ vaip_config.jsonæœªç™ºè¦‹ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šä½¿ç”¨")
        return None
    
    def _create_dummy_onnx_model(self):
        """ãƒ€ãƒŸãƒ¼ONNXãƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆNPUãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        import numpy as np
        import onnx
        from onnx import helper, TensorProto
        
        # ç°¡å˜ãªç·šå½¢å¤‰æ›ãƒ¢ãƒ‡ãƒ«
        input_tensor = helper.make_tensor_value_info('input', TensorProto.FLOAT, [1, 10])
        output_tensor = helper.make_tensor_value_info('output', TensorProto.FLOAT, [1, 10])
        
        # é‡ã¿åˆæœŸåŒ–
        weight_data = np.random.randn(10, 10).astype(np.float32)
        weight_tensor = helper.make_tensor('weight', TensorProto.FLOAT, [10, 10], weight_data.flatten())
        
        # ãƒãƒ¼ãƒ‰ä½œæˆ
        matmul_node = helper.make_node(
            'MatMul',
            inputs=['input', 'weight'],
            outputs=['output'],
            name='matmul'
        )
        
        # ã‚°ãƒ©ãƒ•ä½œæˆ
        graph = helper.make_graph(
            [matmul_node],
            'dummy_npu_model',
            [input_tensor],
            [output_tensor],
            [weight_tensor]
        )
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = helper.make_model(graph)
        model.opset_import[0].version = 11
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        dummy_model_path = "dummy_npu_model.onnx"
        onnx.save(model, dummy_model_path)
        
        print(f"ğŸ“„ ãƒ€ãƒŸãƒ¼ONNXãƒ¢ãƒ‡ãƒ«ä½œæˆ: {dummy_model_path}")
        return dummy_model_path
    
    def test_npu_inference(self, prompt, max_new_tokens=20):
        """NPUæ¨è«–ãƒ†ã‚¹ãƒˆ"""
        if not self.tokenizer or not self.npu_session:
            return "âŒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            
        try:
            print(f"ğŸ”„ NPUæ¨è«–ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {self.timeout}ç§’ï¼‰...")
            
            # æ€§èƒ½ç›£è¦–é–‹å§‹
            self.performance_monitor.start_monitoring()
            
            with TimeoutHandler(self.timeout):
                # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
                inputs = self.tokenizer.encode(prompt, return_tensors="pt")
                print(f"ğŸ“ å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {inputs.shape[1]}")
                
                # NPUæ¨è«–å®Ÿè¡Œï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ï¼‰
                dummy_input = np.random.randn(1, 10).astype(np.float32)
                
                start_time = time.time()
                
                # è¤‡æ•°å›NPUæ¨è«–å®Ÿè¡Œï¼ˆè² è·ãƒ†ã‚¹ãƒˆï¼‰
                for i in range(max_new_tokens):
                    npu_output = self.npu_session.run(None, {'input': dummy_input})
                    
                    # é€²æ—è¡¨ç¤º
                    if i % 5 == 0:
                        print(f"  âš¡ NPUæ¨è«– {i+1}/{max_new_tokens}")
                        
                end_time = time.time()
                
                # æ€§èƒ½ç›£è¦–åœæ­¢
                self.performance_monitor.stop_monitoring()
                
                # çµæœç”Ÿæˆ
                inference_time = end_time - start_time
                throughput = max_new_tokens / inference_time
                
                response = f"""
ğŸ¯ NPUæ¨è«–ãƒ†ã‚¹ãƒˆçµæœ:
ğŸ“ å…¥åŠ›: {prompt}
âš¡ NPUæ¨è«–å›æ•°: {max_new_tokens}
â±ï¸ æ¨è«–æ™‚é–“: {inference_time:.3f}ç§’
ğŸ“Š ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: {throughput:.1f} æ¨è«–/ç§’
ğŸ”§ ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {self.npu_session.get_providers()[0]}
"""
                
            self.generation_count += 1
            return response
            
        except TimeoutException as e:
            self.performance_monitor.stop_monitoring()
            return f"âš ï¸ NPUæ¨è«–ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}"
        except Exception as e:
            self.performance_monitor.stop_monitoring()
            return f"âŒ NPUæ¨è«–ã‚¨ãƒ©ãƒ¼: {e}"
    
    def interactive_mode(self):
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰"""
        print("\nğŸ‡¯ğŸ‡µ ç´”ç²‹NPUãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ  - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰")
        print("âš ï¸ infer-OSæœ€é©åŒ–: ç„¡åŠ¹")
        print(f"â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š: {self.timeout}ç§’")
        print("ğŸ’¡ 'exit'ã¾ãŸã¯'quit'ã§çµ‚äº†ã€'stats'ã§çµ±è¨ˆè¡¨ç¤ºã€'perf'ã§æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 60)
        
        while True:
            try:
                prompt = input("\nğŸ¤– ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
                
                if prompt.lower() in ['exit', 'quit', 'çµ‚äº†']:
                    print("ğŸ‘‹ ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
                    break
                elif prompt.lower() == 'stats':
                    self._show_stats()
                    continue
                elif prompt.lower() == 'perf':
                    print(self.performance_monitor.get_performance_report())
                    continue
                elif not prompt:
                    print("âš ï¸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                    continue
                
                # NPUæ¨è«–ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                response = self.test_npu_inference(prompt)
                print(response)
                
                # æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
                print(self.performance_monitor.get_performance_report())
                
            except KeyboardInterrupt:
                print("\n\nğŸ›‘ Ctrl+CãŒæŠ¼ã•ã‚Œã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
                break
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _show_stats(self):
        """çµ±è¨ˆæƒ…å ±è¡¨ç¤º"""
        print("\nğŸ“Š ç´”ç²‹NPUã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ:")
        print(f"  ğŸ”¢ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå›æ•°: {self.generation_count}")
        print(f"  â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š: {self.timeout}ç§’")
        print(f"  ğŸ¤– ãƒ¢ãƒ‡ãƒ«: {self.model_name}")
        print(f"  âš ï¸ infer-OSæœ€é©åŒ–: {'âŒ ç„¡åŠ¹' if not self.infer_os_enabled else 'âœ… æœ‰åŠ¹'}")
        print(f"  ğŸ”¤ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼: {'âœ… åˆ©ç”¨å¯èƒ½' if self.tokenizer else 'âŒ æœªåˆæœŸåŒ–'}")
        print(f"  âš¡ NPUã‚»ãƒƒã‚·ãƒ§ãƒ³: {'âœ… åˆ©ç”¨å¯èƒ½' if self.npu_session else 'âŒ æœªåˆæœŸåŒ–'}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç´”ç²‹NPUãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆinfer-OSæœ€é©åŒ–OFFï¼‰")
    parser.add_argument("--interactive", action="store_true", help="ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰")
    parser.add_argument("--prompt", type=str, help="å˜ç™ºãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    parser.add_argument("--timeout", type=int, default=60, help="ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 60ç§’ï¼‰")
    parser.add_argument("--model", type=str, default="llama3-8b-amd-npu", help="ãƒ¢ãƒ‡ãƒ«å")
    parser.add_argument("--tokens", type=int, default=20, help="NPUæ¨è«–å›æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰")
    
    args = parser.parse_args()
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = PureNPUSystem(model_name=args.model, timeout=args.timeout)
    
    if not system.setup():
        print("âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)
    
    if args.interactive:
        system.interactive_mode()
    elif args.prompt:
        response = system.test_npu_inference(args.prompt, args.tokens)
        print(response)
    else:
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("  python pure_npu_test_system.py --interactive")
        print("  python pure_npu_test_system.py --prompt \"äººå‚ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„\" --tokens 30")

if __name__ == "__main__":
    main()


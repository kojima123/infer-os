#!/usr/bin/env python3
"""
Phase 1: NPU SRAMéšå±¤å®Ÿè£…
4å±¤ãƒ¡ãƒ¢ãƒªéšå±¤ã¨XDNA SDKçµ±åˆã«ã‚ˆã‚‹æ€§èƒ½å‘ä¸Š

ç›®æ¨™æ€§èƒ½: 13-14 tok/s (20%å‘ä¸Š)
ä¸»è¦å®Ÿè£…: NPU SRAMéšå±¤è¿½åŠ ã€XDNA SDKçµ±åˆã€4å±¤ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–

ä½œæˆè€…: Manus AI
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0
"""

import os
import sys
import time
import json
import logging
import threading
import ctypes
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from enum import Enum

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForCausalLM
import psutil
import numpy as np

# Phase 0 å®Ÿè£…ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from phase0_implementation import (
        SystemConfig as BaseSystemConfig,
        PerformanceMetrics,
        MemoryTier,
        GPUVRAMTier,
        DDRMemoryTier,
        NVMeStorageTier,
        FlexGenPlusPlus as BaseFlexGenPlusPlus,
        InferOSController as BaseInferOSController
    )
except ImportError as e:
    print(f"âŒ Phase 0 å®Ÿè£…ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—: {e}")
    print("phase0_implementation.py ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
    sys.exit(1)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('phase1_implementation.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class NPUTierType(Enum):
    """NPUéšå±¤ã‚¿ã‚¤ãƒ—"""
    SRAM = "NPU_SRAM"
    CACHE_L1 = "NPU_CACHE_L1"
    CACHE_L2 = "NPU_CACHE_L2"

@dataclass
class Phase1SystemConfig(BaseSystemConfig):
    """Phase 1 ã‚·ã‚¹ãƒ†ãƒ è¨­å®š"""
    # NPU SRAMè¨­å®š
    npu_sram_gb: float = 0.008  # 8MB SRAM
    npu_cache_l1_gb: float = 0.001  # 1MB L1ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    npu_cache_l2_gb: float = 0.004  # 4MB L2ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    
    # XDNA SDKè¨­å®š
    xdna_sdk_enabled: bool = True
    npu_compute_units: int = 4
    npu_frequency_mhz: int = 1000
    
    # 4å±¤ãƒ¡ãƒ¢ãƒªéšå±¤è¨­å®š
    enable_4tier_memory: bool = True
    memory_migration_threshold: float = 0.8  # 80%ä½¿ç”¨ç‡ã§ç§»è¡Œ
    
    # Phase 1 æ€§èƒ½ç›®æ¨™
    target_tokens_per_second: float = 13.5  # 20%å‘ä¸Šç›®æ¨™
    target_improvement_ratio: float = 1.2   # Phase 0 æ¯” 20%å‘ä¸Š

@dataclass
class NPUMetrics:
    """NPUæ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    compute_utilization: float = 0.0
    memory_bandwidth_utilization: float = 0.0
    power_consumption_watts: float = 0.0
    temperature_celsius: float = 0.0
    ops_per_second: float = 0.0
    efficiency_tops_per_watt: float = 0.0

class NPUSRAMTier(MemoryTier):
    """NPU SRAMéšå±¤"""
    
    def __init__(self, capacity_gb: float):
        # NPU SRAMã¯è¶…é«˜é€Ÿãƒ»è¶…ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
        super().__init__("NPU_SRAM", capacity_gb, 2000.0)  # 2TB/sç›¸å½“
        self.access_latency_ms = 0.001  # 1Î¼s
        self.npu_optimized = True
        self.tile_size_kb = 64  # 64KB ã‚¿ã‚¤ãƒ«
        self.concurrent_access = 8  # ä¸¦åˆ—ã‚¢ã‚¯ã‚»ã‚¹æ•°
    
    def allocate(self, size_gb: float) -> bool:
        if self.used_gb + size_gb <= self.capacity_gb:
            self.used_gb += size_gb
            self.access_count += 1
            self.total_access_time += self.access_latency_ms
            
            # NPUæœ€é©åŒ–ã•ã‚ŒãŸã‚¢ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³
            self._optimize_npu_allocation(size_gb)
            
            logger.debug(f"NPU SRAM allocated: {size_gb:.6f}GB, total: {self.used_gb:.6f}GB")
            return True
        return False
    
    def deallocate(self, size_gb: float) -> bool:
        if self.used_gb >= size_gb:
            self.used_gb -= size_gb
            logger.debug(f"NPU SRAM deallocated: {size_gb:.6f}GB, remaining: {self.used_gb:.6f}GB")
            return True
        return False
    
    def _optimize_npu_allocation(self, size_gb: float):
        """NPUæœ€é©åŒ–ã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦"""
        # ã‚¿ã‚¤ãƒ«åŒ–ã«ã‚ˆã‚‹åŠ¹ç‡çš„ãªãƒ¡ãƒ¢ãƒªé…ç½®
        size_kb = size_gb * 1024 * 1024
        num_tiles = int(np.ceil(size_kb / self.tile_size_kb))
        
        logger.debug(f"NPU SRAM allocation optimized: {num_tiles} tiles of {self.tile_size_kb}KB")
    
    def get_npu_specific_metrics(self) -> Dict[str, float]:
        """NPUå›ºæœ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—"""
        return {
            "tile_utilization": min(1.0, self.used_gb * 1024 * 1024 / self.tile_size_kb / 128),
            "concurrent_efficiency": min(1.0, self.access_count / self.concurrent_access),
            "bandwidth_efficiency": min(1.0, self.total_access_time / (self.access_count * 0.001))
        }

class XDNASDKInterface:
    """XDNA SDK ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰"""
    
    def __init__(self, config: Phase1SystemConfig):
        self.config = config
        self.initialized = False
        self.npu_handle = None
        self.compute_units = []
        self.current_metrics = NPUMetrics()
        
        # NPUçŠ¶æ…‹
        self.npu_frequency = config.npu_frequency_mhz
        self.compute_utilization = 0.0
        self.power_state = "idle"
    
    def initialize(self) -> bool:
        """XDNA SDK ã®åˆæœŸåŒ–"""
        logger.info("Initializing XDNA SDK interface...")
        
        try:
            # NPUãƒ‡ãƒã‚¤ã‚¹ã®æ¤œå‡ºï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
            if not self._detect_npu_device():
                logger.warning("NPU device not detected, using simulation mode")
            
            # ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆãƒ¦ãƒ‹ãƒƒãƒˆã®åˆæœŸåŒ–
            self._initialize_compute_units()
            
            # ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ã®è¨­å®š
            self._setup_memory_mapping()
            
            self.initialized = True
            logger.info("XDNA SDK initialization completed")
            return True
            
        except Exception as e:
            logger.error(f"XDNA SDK initialization failed: {e}")
            return False
    
    def _detect_npu_device(self) -> bool:
        """NPUãƒ‡ãƒã‚¤ã‚¹ã®æ¤œå‡º"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ã®NPUãƒ‡ãƒã‚¤ã‚¹ã‚’æ¤œå‡º
        # ã“ã“ã§ã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        try:
            # AMD Ryzen AI NPU ã®æ¤œå‡ºã‚’è©¦è¡Œ
            import platform
            if "AMD" in platform.processor() and "Ryzen" in platform.processor():
                logger.info("AMD Ryzen AI NPU detected")
                return True
        except:
            pass
        
        logger.info("Using NPU simulation mode")
        return False
    
    def _initialize_compute_units(self):
        """ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆãƒ¦ãƒ‹ãƒƒãƒˆã®åˆæœŸåŒ–"""
        for i in range(self.config.npu_compute_units):
            compute_unit = {
                "id": i,
                "status": "idle",
                "utilization": 0.0,
                "assigned_tasks": []
            }
            self.compute_units.append(compute_unit)
        
        logger.info(f"Initialized {len(self.compute_units)} NPU compute units")
    
    def _setup_memory_mapping(self):
        """ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ã®è¨­å®š"""
        # NPU SRAMã¸ã®ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š
        logger.info("NPU memory mapping configured")
    
    def allocate_npu_memory(self, size_bytes: int) -> Optional[int]:
        """NPUãƒ¡ãƒ¢ãƒªã®å‰²ã‚Šå½“ã¦"""
        if not self.initialized:
            return None
        
        # NPU SRAMã¸ã®å‰²ã‚Šå½“ã¦ï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        handle = hash(f"npu_mem_{time.time()}_{size_bytes}") % 1000000
        logger.debug(f"NPU memory allocated: {size_bytes} bytes, handle: {handle}")
        return handle
    
    def deallocate_npu_memory(self, handle: int) -> bool:
        """NPUãƒ¡ãƒ¢ãƒªã®è§£æ”¾"""
        if not self.initialized:
            return False
        
        logger.debug(f"NPU memory deallocated: handle {handle}")
        return True
    
    def execute_npu_kernel(self, kernel_data: Dict[str, Any]) -> bool:
        """NPUã‚«ãƒ¼ãƒãƒ«ã®å®Ÿè¡Œ"""
        if not self.initialized:
            return False
        
        # åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆãƒ¦ãƒ‹ãƒƒãƒˆã‚’æ¤œç´¢
        available_unit = None
        for unit in self.compute_units:
            if unit["status"] == "idle":
                available_unit = unit
                break
        
        if not available_unit:
            logger.warning("No available NPU compute units")
            return False
        
        # ã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        available_unit["status"] = "busy"
        available_unit["utilization"] = 0.8
        
        # å®Ÿè¡Œæ™‚é–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        execution_time = kernel_data.get("estimated_time_ms", 1.0)
        
        def complete_execution():
            time.sleep(execution_time / 1000.0)
            available_unit["status"] = "idle"
            available_unit["utilization"] = 0.0
        
        # éåŒæœŸå®Ÿè¡Œ
        threading.Thread(target=complete_execution, daemon=True).start()
        
        logger.debug(f"NPU kernel executed on unit {available_unit['id']}")
        return True
    
    def get_npu_metrics(self) -> NPUMetrics:
        """NPUãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—"""
        # ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒˆãƒ¦ãƒ‹ãƒƒãƒˆã®å¹³å‡ä½¿ç”¨ç‡
        total_utilization = sum(unit["utilization"] for unit in self.compute_units)
        avg_utilization = total_utilization / len(self.compute_units)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°
        self.current_metrics.compute_utilization = avg_utilization
        self.current_metrics.memory_bandwidth_utilization = min(1.0, avg_utilization * 1.2)
        self.current_metrics.power_consumption_watts = 15.0 * avg_utilization  # æœ€å¤§15W
        self.current_metrics.temperature_celsius = 45.0 + (20.0 * avg_utilization)
        self.current_metrics.ops_per_second = 50e12 * avg_utilization  # 50 TOPS
        
        if self.current_metrics.power_consumption_watts > 0:
            self.current_metrics.efficiency_tops_per_watt = (
                self.current_metrics.ops_per_second / 1e12 / self.current_metrics.power_consumption_watts
            )
        
        return self.current_metrics
    
    def optimize_npu_frequency(self, target_utilization: float = 0.8):
        """NPUå‘¨æ³¢æ•°ã®æœ€é©åŒ–"""
        current_utilization = self.current_metrics.compute_utilization
        
        if current_utilization > target_utilization:
            # ä½¿ç”¨ç‡ãŒé«˜ã„å ´åˆã¯å‘¨æ³¢æ•°ã‚’ä¸Šã’ã‚‹
            new_frequency = min(self.config.npu_frequency_mhz * 1.1, 1200)
        elif current_utilization < target_utilization * 0.5:
            # ä½¿ç”¨ç‡ãŒä½ã„å ´åˆã¯å‘¨æ³¢æ•°ã‚’ä¸‹ã’ã‚‹ï¼ˆçœé›»åŠ›ï¼‰
            new_frequency = max(self.config.npu_frequency_mhz * 0.9, 800)
        else:
            new_frequency = self.npu_frequency
        
        if abs(new_frequency - self.npu_frequency) > 10:
            self.npu_frequency = new_frequency
            logger.debug(f"NPU frequency adjusted to {self.npu_frequency} MHz")

class FourTierMemoryManager:
    """4å±¤ãƒ¡ãƒ¢ãƒªéšå±¤ç®¡ç†"""
    
    def __init__(self, config: Phase1SystemConfig):
        self.config = config
        
        # 4å±¤ãƒ¡ãƒ¢ãƒªéšå±¤ã®æ§‹ç¯‰
        self.tiers = [
            NPUSRAMTier(config.npu_sram_gb),           # Tier 0: NPU SRAM
            GPUVRAMTier(config.gpu_vram_gb),           # Tier 1: GPU VRAM
            DDRMemoryTier(config.ddr_memory_gb),       # Tier 2: DDR Memory
            NVMeStorageTier(config.nvme_storage_gb)    # Tier 3: NVMe Storage
        ]
        
        self.allocation_history = []
        self.migration_history = []
        self.access_patterns = {}
        
        # éšå±¤é–“ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã®çµ±è¨ˆ
        self.migration_stats = {
            "total_migrations": 0,
            "successful_migrations": 0,
            "migration_time_total": 0.0
        }
    
    def allocate_intelligent(self, size_gb: float, 
                           access_pattern: str = "sequential",
                           priority: str = "performance") -> Optional[MemoryTier]:
        """ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦"""
        
        # ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæœ€é©éšå±¤ã®æ±ºå®š
        optimal_tier_index = self._determine_optimal_tier(size_gb, access_pattern, priority)
        
        # æœ€é©éšå±¤ã‹ã‚‰é †ã«å‰²ã‚Šå½“ã¦ã‚’è©¦è¡Œ
        for i in range(optimal_tier_index, len(self.tiers)):
            tier = self.tiers[i]
            if tier.allocate(size_gb):
                self._record_allocation(tier, size_gb, access_pattern)
                return tier
        
        # å…¨ã¦ã®éšå±¤ã§å‰²ã‚Šå½“ã¦ã«å¤±æ•—ã—ãŸå ´åˆã€ãƒ¡ãƒ¢ãƒªç§»è¡Œã‚’è©¦è¡Œ
        if self._attempt_memory_migration(size_gb):
            return self.allocate_intelligent(size_gb, access_pattern, priority)
        
        logger.warning(f"Failed to allocate {size_gb:.6f}GB in any tier")
        return None
    
    def _determine_optimal_tier(self, size_gb: float, access_pattern: str, priority: str) -> int:
        """æœ€é©éšå±¤ã®æ±ºå®š"""
        
        # NPU SRAM: å°ã•ãªã‚µã‚¤ã‚ºã€é«˜é »åº¦ã‚¢ã‚¯ã‚»ã‚¹
        if size_gb <= 0.002 and access_pattern in ["random", "high_frequency"]:
            return 0
        
        # GPU VRAM: ä¸­ç¨‹åº¦ã®ã‚µã‚¤ã‚ºã€è¨ˆç®—é›†ç´„çš„
        elif size_gb <= 2.0 and priority == "performance":
            return 1
        
        # DDR Memory: å¤§ããªã‚µã‚¤ã‚ºã€é †æ¬¡ã‚¢ã‚¯ã‚»ã‚¹
        elif size_gb <= 8.0:
            return 2
        
        # NVMe Storage: éå¸¸ã«å¤§ããªã‚µã‚¤ã‚º
        else:
            return 3
    
    def _record_allocation(self, tier: MemoryTier, size_gb: float, access_pattern: str):
        """å‰²ã‚Šå½“ã¦è¨˜éŒ²"""
        allocation_record = {
            "tier": tier.name,
            "size_gb": size_gb,
            "access_pattern": access_pattern,
            "timestamp": time.time()
        }
        
        self.allocation_history.append(allocation_record)
        
        # ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±è¨ˆæ›´æ–°
        if access_pattern not in self.access_patterns:
            self.access_patterns[access_pattern] = {"count": 0, "total_size": 0.0}
        
        self.access_patterns[access_pattern]["count"] += 1
        self.access_patterns[access_pattern]["total_size"] += size_gb
    
    def _attempt_memory_migration(self, required_size_gb: float) -> bool:
        """ãƒ¡ãƒ¢ãƒªç§»è¡Œã®è©¦è¡Œ"""
        self.migration_stats["total_migrations"] += 1
        migration_start_time = time.time()
        
        # ä½¿ç”¨ç‡ã®é«˜ã„éšå±¤ã‹ã‚‰ä½ã„éšå±¤ã¸ã®ç§»è¡Œã‚’æ¤œè¨
        for i, source_tier in enumerate(self.tiers[:-1]):
            if source_tier.get_utilization() > self.config.memory_migration_threshold:
                target_tier = self.tiers[i + 1]
                
                # ç§»è¡Œå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®è¨ˆç®—
                migration_size = min(
                    source_tier.used_gb * 0.3,  # 30%ã‚’ç§»è¡Œ
                    target_tier.capacity_gb - target_tier.used_gb,
                    required_size_gb * 2  # å¿…è¦ã‚µã‚¤ã‚ºã®2å€ã¾ã§
                )
                
                if migration_size > 0:
                    # ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã®å®Ÿè¡Œ
                    if self._execute_migration(source_tier, target_tier, migration_size):
                        migration_time = time.time() - migration_start_time
                        self.migration_stats["successful_migrations"] += 1
                        self.migration_stats["migration_time_total"] += migration_time
                        
                        logger.info(f"Memory migration: {migration_size:.3f}GB from {source_tier.name} to {target_tier.name}")
                        return True
        
        return False
    
    def _execute_migration(self, source_tier: MemoryTier, target_tier: MemoryTier, size_gb: float) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ç§»è¡Œã®å®Ÿè¡Œ"""
        # ç§»è¡Œã®å®Ÿè¡Œï¼ˆç°¡ç•¥åŒ–ï¼‰
        if source_tier.deallocate(size_gb) and target_tier.allocate(size_gb):
            self.migration_history.append({
                "source": source_tier.name,
                "target": target_tier.name,
                "size_gb": size_gb,
                "timestamp": time.time()
            })
            return True
        return False
    
    def get_4tier_status(self) -> Dict[str, Any]:
        """4å±¤ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã®å–å¾—"""
        status = {}
        
        for i, tier in enumerate(self.tiers):
            tier_status = {
                "tier_index": i,
                "capacity_gb": tier.capacity_gb,
                "used_gb": tier.used_gb,
                "utilization": tier.get_utilization(),
                "bandwidth_gbps": tier.bandwidth_gbps,
                "avg_access_time_ms": tier.get_average_access_time()
            }
            
            # NPU SRAMå›ºæœ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            if isinstance(tier, NPUSRAMTier):
                tier_status.update(tier.get_npu_specific_metrics())
            
            status[tier.name] = tier_status
        
        # ç§»è¡Œçµ±è¨ˆã®è¿½åŠ 
        status["migration_stats"] = self.migration_stats
        status["access_patterns"] = self.access_patterns
        
        return status
    
    def optimize_4tier_allocation(self):
        """4å±¤ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã®æœ€é©åŒ–"""
        # ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãæœ€é©åŒ–
        for pattern, stats in self.access_patterns.items():
            if stats["count"] > 10:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«æ•°
                avg_size = stats["total_size"] / stats["count"]
                
                # é«˜é »åº¦ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’NPU SRAMã«å„ªå…ˆé…ç½®
                if pattern == "high_frequency" and avg_size < 0.001:
                    logger.debug(f"Optimizing allocation for pattern: {pattern}")

class FlexGenPlusPlusPhase1(BaseFlexGenPlusPlus):
    """FlexGen++ Phase 1 å®Ÿè£…"""
    
    def __init__(self, config: Phase1SystemConfig):
        # Phase 0 ã®åˆæœŸåŒ–
        super().__init__(config)
        
        # Phase 1 å›ºæœ‰ã®è¨­å®š
        self.config = config
        self.memory_manager = FourTierMemoryManager(config)
        self.xdna_sdk = XDNASDKInterface(config)
        
        # NPUæœ€é©åŒ–è¨­å®š
        self.npu_optimized_layers = []
        self.npu_kernel_cache = {}
        self.npu_memory_handles = {}
        
        # Phase 1 æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.phase1_metrics = {
            "npu_utilization": 0.0,
            "4tier_efficiency": 0.0,
            "memory_migration_count": 0,
            "npu_kernel_executions": 0
        }
    
    def initialize_model(self) -> bool:
        """Phase 1 ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        logger.info("Initializing FlexGen++ Phase 1...")
        
        # XDNA SDK ã®åˆæœŸåŒ–
        if self.config.xdna_sdk_enabled:
            if not self.xdna_sdk.initialize():
                logger.warning("XDNA SDK initialization failed, continuing without NPU acceleration")
        
        # Phase 0 ã®ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        if not super().initialize_model():
            return False
        
        # NPUæœ€é©åŒ–ã®é©ç”¨
        if self.config.xdna_sdk_enabled:
            self._optimize_model_for_npu()
        
        # 4å±¤ãƒ¡ãƒ¢ãƒªéšå±¤ã§ã®æœ€é©é…ç½®
        self._optimize_memory_placement()
        
        logger.info("FlexGen++ Phase 1 initialization completed")
        return True
    
    def _optimize_model_for_npu(self):
        """NPUå‘ã‘ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ–"""
        logger.info("Optimizing model for NPU...")
        
        # Attentionå±¤ã®NPUæœ€é©åŒ–
        for name, module in self.model.named_modules():
            if "attention" in name.lower():
                self._optimize_attention_for_npu(name, module)
        
        # FFNå±¤ã®NPUæœ€é©åŒ–
        for name, module in self.model.named_modules():
            if "mlp" in name.lower() or "ffn" in name.lower():
                self._optimize_ffn_for_npu(name, module)
        
        logger.info(f"Optimized {len(self.npu_optimized_layers)} layers for NPU")
    
    def _optimize_attention_for_npu(self, name: str, module: nn.Module):
        """Attentionå±¤ã®NPUæœ€é©åŒ–"""
        # NPUå‘ã‘Attentionæœ€é©åŒ–
        optimization_config = {
            "layer_name": name,
            "optimization_type": "attention",
            "npu_kernel": "optimized_attention",
            "memory_tier": "NPU_SRAM"
        }
        
        self.npu_optimized_layers.append(optimization_config)
        logger.debug(f"NPU optimized attention layer: {name}")
    
    def _optimize_ffn_for_npu(self, name: str, module: nn.Module):
        """FFNå±¤ã®NPUæœ€é©åŒ–"""
        # NPUå‘ã‘FFNæœ€é©åŒ–
        optimization_config = {
            "layer_name": name,
            "optimization_type": "ffn",
            "npu_kernel": "optimized_ffn",
            "memory_tier": "NPU_SRAM"
        }
        
        self.npu_optimized_layers.append(optimization_config)
        logger.debug(f"NPU optimized FFN layer: {name}")
    
    def _optimize_memory_placement(self):
        """4å±¤ãƒ¡ãƒ¢ãƒªéšå±¤ã§ã®æœ€é©é…ç½®"""
        logger.info("Optimizing memory placement in 4-tier hierarchy...")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®éšå±¤åˆ¥é…ç½®
        total_params = sum(p.numel() * p.element_size() for p in self.model.parameters())
        total_size_gb = total_params / (1024**3)
        
        # é‡è¦åº¦ã«åŸºã¥ãéšå±¤é…ç½®
        critical_size_gb = total_size_gb * 0.1  # 10%ã‚’NPU SRAMã«
        important_size_gb = total_size_gb * 0.3  # 30%ã‚’GPU VRAMã«
        
        # NPU SRAMã¸ã®é…ç½®
        npu_tier = self.memory_manager.allocate_intelligent(
            critical_size_gb, "high_frequency", "performance"
        )
        
        # GPU VRAMã¸ã®é…ç½®
        gpu_tier = self.memory_manager.allocate_intelligent(
            important_size_gb, "sequential", "performance"
        )
        
        logger.info(f"Memory placement: NPU SRAM {critical_size_gb:.3f}GB, GPU VRAM {important_size_gb:.3f}GB")
    
    def execute_inference(self, prompt: str, max_tokens: int = 100) -> Tuple[str, PerformanceMetrics]:
        """Phase 1 æ¨è«–å®Ÿè¡Œ"""
        start_time = time.time()
        
        # NPUãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—ï¼ˆé–‹å§‹æ™‚ï¼‰
        npu_metrics_start = self.xdna_sdk.get_npu_metrics() if self.config.xdna_sdk_enabled else NPUMetrics()
        
        # Phase 0 ã®æ¨è«–å®Ÿè¡Œ
        response, base_metrics = super().execute_inference(prompt, max_tokens)
        
        # NPUæœ€é©åŒ–ã®é©ç”¨
        if self.config.xdna_sdk_enabled:
            self._apply_npu_optimizations()
        
        # 4å±¤ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®å®Ÿè¡Œ
        self.memory_manager.optimize_4tier_allocation()
        
        # NPUãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å–å¾—ï¼ˆçµ‚äº†æ™‚ï¼‰
        npu_metrics_end = self.xdna_sdk.get_npu_metrics() if self.config.xdna_sdk_enabled else NPUMetrics()
        
        # Phase 1 ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°
        self._update_phase1_metrics(npu_metrics_start, npu_metrics_end)
        
        end_time = time.time()
        inference_time = end_time - start_time
        
        # æ€§èƒ½å‘ä¸Šã®è¨ˆç®—
        improvement_ratio = base_metrics.tokens_per_second / 11.0  # Phase 0 åŸºæº–
        
        logger.info(f"Phase 1 inference: {base_metrics.tokens_per_second:.1f} tok/s, improvement: {improvement_ratio:.1%}")
        
        return response, base_metrics
    
    def _apply_npu_optimizations(self):
        """NPUæœ€é©åŒ–ã®é©ç”¨"""
        for optimization in self.npu_optimized_layers:
            kernel_data = {
                "layer_name": optimization["layer_name"],
                "kernel_type": optimization["npu_kernel"],
                "estimated_time_ms": 0.5
            }
            
            if self.xdna_sdk.execute_npu_kernel(kernel_data):
                self.phase1_metrics["npu_kernel_executions"] += 1
    
    def _update_phase1_metrics(self, npu_start: NPUMetrics, npu_end: NPUMetrics):
        """Phase 1 ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°"""
        self.phase1_metrics["npu_utilization"] = npu_end.compute_utilization
        
        # 4å±¤ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è¨ˆç®—
        memory_status = self.memory_manager.get_4tier_status()
        total_utilization = sum(
            tier["utilization"] for tier in memory_status.values() 
            if isinstance(tier, dict) and "utilization" in tier
        )
        self.phase1_metrics["4tier_efficiency"] = total_utilization / 4.0
        
        # ãƒ¡ãƒ¢ãƒªç§»è¡Œå›æ•°ã®æ›´æ–°
        self.phase1_metrics["memory_migration_count"] = memory_status.get("migration_stats", {}).get("total_migrations", 0)
    
    def get_phase1_performance_summary(self) -> Dict[str, Any]:
        """Phase 1 æ€§èƒ½ã‚µãƒãƒªãƒ¼ã®å–å¾—"""
        base_summary = super().get_performance_summary()
        
        if "error" in base_summary:
            return base_summary
        
        # Phase 1 å›ºæœ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½åŠ 
        phase1_summary = base_summary.copy()
        phase1_summary.update({
            "phase1_metrics": self.phase1_metrics,
            "4tier_memory_status": self.memory_manager.get_4tier_status(),
            "npu_metrics": self.xdna_sdk.get_npu_metrics() if self.config.xdna_sdk_enabled else None,
            "improvement_over_phase0": phase1_summary["average_tokens_per_second"] / 11.0,
            "target_achievement_phase1": phase1_summary["average_tokens_per_second"] / self.config.target_tokens_per_second
        })
        
        return phase1_summary

class InferOSControllerPhase1(BaseInferOSController):
    """Infer-OS Phase 1 åˆ¶å¾¡æ©Ÿæ§‹"""
    
    def __init__(self, config: Phase1SystemConfig):
        # Phase 0 ã®åˆæœŸåŒ–ï¼ˆFlexGenã‚’Phase1ç‰ˆã«ç½®ãæ›ãˆï¼‰
        self.config = config
        self.flexgen = FlexGenPlusPlusPhase1(config)
        self.control_thread = None
        self.running = False
        self.control_metrics = []
        
        # Phase 1 å›ºæœ‰ã®åˆ¶å¾¡çŠ¶æ…‹
        self.npu_controller = NPUController(config)
        self.memory_4tier_controller = Memory4TierController(config)
        
        # åˆ¶å¾¡çŠ¶æ…‹
        self.current_load = 0.0
        self.target_performance = config.target_tokens_per_second
        self.control_actions = []
        
        # Phase 1 åˆ¶å¾¡çµ±è¨ˆ
        self.phase1_control_stats = {
            "npu_optimizations": 0,
            "memory_migrations": 0,
            "frequency_adjustments": 0,
            "performance_improvements": []
        }
    
    def _monitor_system_state(self) -> Dict[str, Any]:
        """Phase 1 ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç›£è¦–"""
        # Phase 0 ã®ç›£è¦–ã«åŠ ãˆã¦ Phase 1 å›ºæœ‰ã®ç›£è¦–
        base_state = super()._monitor_system_state()
        
        # NPUçŠ¶æ…‹ã®ç›£è¦–
        npu_metrics = self.flexgen.xdna_sdk.get_npu_metrics() if self.config.xdna_sdk_enabled else NPUMetrics()
        
        # 4å±¤ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹ã®ç›£è¦–
        memory_4tier_status = self.flexgen.memory_manager.get_4tier_status()
        
        # Phase 1 å›ºæœ‰çŠ¶æ…‹ã®è¿½åŠ 
        phase1_state = base_state.copy()
        phase1_state.update({
            "npu_metrics": {
                "compute_utilization": npu_metrics.compute_utilization,
                "memory_bandwidth_utilization": npu_metrics.memory_bandwidth_utilization,
                "power_consumption": npu_metrics.power_consumption_watts,
                "temperature": npu_metrics.temperature_celsius
            },
            "memory_4tier": memory_4tier_status,
            "phase1_performance": self.flexgen.phase1_metrics
        })
        
        return phase1_state
    
    def _make_control_decision(self, system_state: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Phase 1 åˆ¶å¾¡åˆ¤æ–­"""
        control_action = None
        
        # NPUä½¿ç”¨ç‡ã«åŸºã¥ãåˆ¶å¾¡
        npu_utilization = system_state.get("npu_metrics", {}).get("compute_utilization", 0.0)
        
        if npu_utilization < 0.3:  # NPUä½¿ç”¨ç‡ãŒä½ã„
            control_action = {
                "type": "npu_optimization",
                "action": "increase_npu_workload",
                "priority": "high",
                "target_utilization": 0.7
            }
        
        elif npu_utilization > 0.9:  # NPUä½¿ç”¨ç‡ãŒé«˜ã™ãã‚‹
            control_action = {
                "type": "npu_optimization", 
                "action": "reduce_npu_workload",
                "priority": "medium",
                "target_utilization": 0.8
            }
        
        # 4å±¤ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ã«åŸºã¥ãåˆ¶å¾¡
        elif self._check_memory_imbalance(system_state):
            control_action = {
                "type": "memory_4tier_optimization",
                "action": "rebalance_memory_allocation",
                "priority": "medium"
            }
        
        # Phase 0 ã®åˆ¶å¾¡åˆ¤æ–­ã‚‚è€ƒæ…®
        if not control_action:
            control_action = super()._make_control_decision(system_state)
        
        return control_action
    
    def _check_memory_imbalance(self, system_state: Dict[str, Any]) -> bool:
        """4å±¤ãƒ¡ãƒ¢ãƒªã®ä¸å‡è¡¡ãƒã‚§ãƒƒã‚¯"""
        memory_4tier = system_state.get("memory_4tier", {})
        
        utilizations = []
        for tier_name, tier_data in memory_4tier.items():
            if isinstance(tier_data, dict) and "utilization" in tier_data:
                utilizations.append(tier_data["utilization"])
        
        if len(utilizations) >= 2:
            max_util = max(utilizations)
            min_util = min(utilizations)
            
            # ä½¿ç”¨ç‡ã®å·®ãŒ50%ä»¥ä¸Šã®å ´åˆã¯ä¸å‡è¡¡ã¨åˆ¤å®š
            return (max_util - min_util) > 0.5
        
        return False
    
    def _execute_control_action(self, action: Dict[str, Any]):
        """Phase 1 åˆ¶å¾¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        action_type = action.get("type")
        
        if action_type == "npu_optimization":
            self._execute_npu_optimization(action)
        
        elif action_type == "memory_4tier_optimization":
            self._execute_memory_4tier_optimization(action)
        
        else:
            # Phase 0 ã®åˆ¶å¾¡ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            super()._execute_control_action(action)
        
        # Phase 1 çµ±è¨ˆã®æ›´æ–°
        self._update_phase1_control_stats(action)
    
    def _execute_npu_optimization(self, action: Dict[str, Any]):
        """NPUæœ€é©åŒ–ã®å®Ÿè¡Œ"""
        action_name = action.get("action")
        
        if action_name == "increase_npu_workload":
            # NPUãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å¢—åŠ 
            self.npu_controller.increase_workload()
            self.phase1_control_stats["npu_optimizations"] += 1
            
        elif action_name == "reduce_npu_workload":
            # NPUãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å‰Šæ¸›
            self.npu_controller.reduce_workload()
            self.phase1_control_stats["npu_optimizations"] += 1
        
        logger.info(f"NPU optimization executed: {action_name}")
    
    def _execute_memory_4tier_optimization(self, action: Dict[str, Any]):
        """4å±¤ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã®å®Ÿè¡Œ"""
        # ãƒ¡ãƒ¢ãƒªå†é…ç½®ã®å®Ÿè¡Œ
        self.memory_4tier_controller.rebalance_allocation()
        self.phase1_control_stats["memory_migrations"] += 1
        
        logger.info("4-tier memory optimization executed")
    
    def _update_phase1_control_stats(self, action: Dict[str, Any]):
        """Phase 1 åˆ¶å¾¡çµ±è¨ˆã®æ›´æ–°"""
        self.control_actions.append({
            "timestamp": time.time(),
            "action": action,
            "phase": "phase1"
        })
    
    def get_phase1_system_status(self) -> Dict[str, Any]:
        """Phase 1 ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®å–å¾—"""
        base_status = super().get_system_status()
        
        # Phase 1 å›ºæœ‰çŠ¶æ…‹ã®è¿½åŠ 
        phase1_status = base_status.copy()
        phase1_status.update({
            "phase1_control_stats": self.phase1_control_stats,
            "npu_controller_status": self.npu_controller.get_status(),
            "memory_4tier_controller_status": self.memory_4tier_controller.get_status(),
            "phase1_performance": self.flexgen.get_phase1_performance_summary()
        })
        
        return phase1_status

class NPUController:
    """NPUåˆ¶å¾¡æ©Ÿæ§‹"""
    
    def __init__(self, config: Phase1SystemConfig):
        self.config = config
        self.current_workload = 0.0
        self.target_workload = 0.7
        self.workload_history = []
    
    def increase_workload(self):
        """NPUãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å¢—åŠ """
        self.current_workload = min(1.0, self.current_workload + 0.1)
        self.workload_history.append({
            "timestamp": time.time(),
            "action": "increase",
            "workload": self.current_workload
        })
    
    def reduce_workload(self):
        """NPUãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰ã®å‰Šæ¸›"""
        self.current_workload = max(0.0, self.current_workload - 0.1)
        self.workload_history.append({
            "timestamp": time.time(),
            "action": "reduce", 
            "workload": self.current_workload
        })
    
    def get_status(self) -> Dict[str, Any]:
        """NPUåˆ¶å¾¡çŠ¶æ…‹ã®å–å¾—"""
        return {
            "current_workload": self.current_workload,
            "target_workload": self.target_workload,
            "workload_adjustments": len(self.workload_history)
        }

class Memory4TierController:
    """4å±¤ãƒ¡ãƒ¢ãƒªåˆ¶å¾¡æ©Ÿæ§‹"""
    
    def __init__(self, config: Phase1SystemConfig):
        self.config = config
        self.rebalance_count = 0
        self.last_rebalance_time = 0.0
    
    def rebalance_allocation(self):
        """ãƒ¡ãƒ¢ãƒªå‰²ã‚Šå½“ã¦ã®å†é…ç½®"""
        current_time = time.time()
        
        # æœ€ä½1ç§’é–“éš”ã§ã®å†é…ç½®
        if current_time - self.last_rebalance_time > 1.0:
            self.rebalance_count += 1
            self.last_rebalance_time = current_time
            logger.debug("Memory 4-tier rebalancing executed")
    
    def get_status(self) -> Dict[str, Any]:
        """4å±¤ãƒ¡ãƒ¢ãƒªåˆ¶å¾¡çŠ¶æ…‹ã®å–å¾—"""
        return {
            "rebalance_count": self.rebalance_count,
            "last_rebalance_time": self.last_rebalance_time
        }

def run_phase1_benchmark():
    """Phase 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®å®Ÿè¡Œ"""
    logger.info("Starting Phase 1 benchmark...")
    
    # Phase 1 ã‚·ã‚¹ãƒ†ãƒ è¨­å®š
    config = Phase1SystemConfig()
    
    # Infer-OS Phase 1 ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    inferos = InferOSControllerPhase1(config)
    
    if not inferos.initialize_system():
        logger.error("Phase 1 system initialization failed")
        return
    
    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆPhase 0 ã‚ˆã‚Šè¤‡é›‘ï¼‰
    test_prompts = [
        "Explain the principles of quantum computing and its potential applications in artificial intelligence.",
        "Write a comprehensive Python program that implements a neural network from scratch.",
        "Describe the historical development of machine learning and its impact on modern technology.",
        "äººå·¥çŸ¥èƒ½ã®ç™ºå±•ãŒç¤¾ä¼šã«ä¸ãˆã‚‹å½±éŸ¿ã«ã¤ã„ã¦ã€æŠ€è¡“çš„ãƒ»å€«ç†çš„è¦³ç‚¹ã‹ã‚‰è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "Create a detailed analysis of the differences between supervised and unsupervised learning algorithms."
    ]
    
    logger.info("Executing Phase 1 benchmark tests...")
    
    total_start_time = time.time()
    all_metrics = []
    
    for i, prompt in enumerate(test_prompts):
        logger.info(f"Phase 1 Test {i+1}/{len(test_prompts)}: {prompt[:60]}...")
        
        try:
            response, metrics = inferos.execute_inference_request(prompt, max_tokens=150)
            all_metrics.append(metrics)
            
            logger.info(f"Response length: {len(response)} chars")
            logger.info(f"Performance: {metrics.tokens_per_second:.1f} tok/s")
            
        except Exception as e:
            logger.error(f"Phase 1 Test {i+1} failed: {e}")
    
    total_time = time.time() - total_start_time
    
    # Phase 1 çµæœã®é›†è¨ˆ
    if all_metrics:
        avg_tokens_per_second = sum(m.tokens_per_second for m in all_metrics) / len(all_metrics)
        avg_latency = sum(m.latency_ms for m in all_metrics) / len(all_metrics)
        
        # Phase 0 ã¨ã®æ¯”è¼ƒ
        phase0_baseline = 11.0
        improvement_ratio = avg_tokens_per_second / phase0_baseline
        
        logger.info("=== Phase 1 Benchmark Results ===")
        logger.info(f"Total tests: {len(all_metrics)}")
        logger.info(f"Total time: {total_time:.2f} seconds")
        logger.info(f"Average tokens/second: {avg_tokens_per_second:.1f}")
        logger.info(f"Average latency: {avg_latency:.1f} ms")
        logger.info(f"Phase 0 baseline: {phase0_baseline} tok/s")
        logger.info(f"Improvement over Phase 0: {improvement_ratio:.1%}")
        logger.info(f"Phase 1 target achievement: {avg_tokens_per_second/config.target_tokens_per_second:.1%}")
        
        # Phase 1 ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®è¡¨ç¤º
        system_status = inferos.get_phase1_system_status()
        logger.info("Phase 1 System Status:")
        logger.info(f"  NPU optimizations: {system_status['phase1_control_stats']['npu_optimizations']}")
        logger.info(f"  Memory migrations: {system_status['phase1_control_stats']['memory_migrations']}")
        
        # ç›®æ¨™é”æˆã®ç¢ºèª
        if avg_tokens_per_second >= config.target_tokens_per_second:
            logger.info("âœ… Phase 1 target achieved!")
        else:
            gap = config.target_tokens_per_second - avg_tokens_per_second
            logger.warning(f"âš ï¸ Phase 1 target not achieved. Gap: {gap:.1f} tok/s")
        
        # æ”¹å–„ç‡ã®ç¢ºèª
        if improvement_ratio >= config.target_improvement_ratio:
            logger.info("âœ… Phase 1 improvement target achieved!")
        else:
            logger.warning(f"âš ï¸ Phase 1 improvement target not achieved. Current: {improvement_ratio:.1%}, Target: {config.target_improvement_ratio:.1%}")
    
    # ã‚·ã‚¹ãƒ†ãƒ ã®åœæ­¢
    inferos.stop_control_loop()
    logger.info("Phase 1 benchmark completed")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸš€ Phase 1: NPU SRAMéšå±¤å®Ÿè£…")
    print("=" * 50)
    
    try:
        run_phase1_benchmark()
    except KeyboardInterrupt:
        logger.info("Phase 1 benchmark interrupted by user")
    except Exception as e:
        logger.error(f"Phase 1 benchmark failed: {e}")
        raise

if __name__ == "__main__":
    main()


# ğŸš€ çµ±åˆNPU + Infer-OSæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

**çµ±åˆNPU + Infer-OSæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ **ã¯ã€AMD Ryzen AI NPUã¨Infer-OSæœ€é©åŒ–æŠ€è¡“ã‚’çµ„ã¿åˆã‚ã›ãŸã€çœŸã®åŒ…æ‹¬çš„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚æ—¥æœ¬èªç‰¹åŒ–ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã§æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### ğŸ¯ ä¸»è¦æ©Ÿèƒ½

- âš¡ **NPUæœ€é©åŒ–**: VitisAI ExecutionProviderã«ã‚ˆã‚‹çœŸã®NPUå‡¦ç†
- ğŸ§  **Infer-OSæœ€é©åŒ–**: ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã€é«˜åº¦é‡å­åŒ–
- ğŸªŸ **Windows NPUæœ€é©åŒ–**: AMD/Intel/Qualcomm NPUå¯¾å¿œ
- ğŸ‡¯ğŸ‡µ **æ—¥æœ¬èªç‰¹åŒ–**: 8B-70Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«å¯¾å¿œ
- ğŸ“Š **åŒ…æ‹¬çš„ç›£è¦–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§èƒ½ç›£è¦–ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
- ğŸ® **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–**: å¯¾è©±å‹ãƒ‡ãƒ¢ã¨ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ©Ÿèƒ½

## ğŸ—ï¸ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
infer-os/
â”œâ”€â”€ integrated_npu_infer_os.py          # çµ±åˆæœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
â”œâ”€â”€ run_integrated_demo.py              # åŒ…æ‹¬çš„ãƒ‡ãƒ¢ã‚·ã‚¹ãƒ†ãƒ 
â”œâ”€â”€ test_integrated_system.py           # æ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
â”œâ”€â”€ npu_optimized_japanese_models.py    # NPUæœ€é©åŒ–æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ download_npu_models.py              # ãƒ¢ãƒ‡ãƒ«è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
â”œâ”€â”€ vitisai_npu_engine.py               # VitisAI NPUå°‚ç”¨ã‚¨ãƒ³ã‚¸ãƒ³
â”œâ”€â”€ run_vitisai_demo.py                 # VitisAI NPUãƒ‡ãƒ¢
â”œâ”€â”€ infer_os_japanese_llm_demo.py       # Infer-OSæœ€é©åŒ–ãƒ‡ãƒ¢
â””â”€â”€ INTEGRATED_NPU_INFER_OS_GUIDE.md    # æœ¬ã‚¬ã‚¤ãƒ‰
```

### ğŸ”§ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    A[çµ±åˆNPU + Infer-OSæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ] --> B[NPUæœ€é©åŒ–å±¤]
    A --> C[Infer-OSæœ€é©åŒ–å±¤]
    A --> D[ãƒ¢ãƒ‡ãƒ«ç®¡ç†å±¤]
    A --> E[ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å±¤]
    
    B --> B1[VitisAI ExecutionProvider]
    B --> B2[qlinearé‡å­åŒ–]
    B --> B3[NPUç’°å¢ƒè¨­å®š]
    
    C --> C1[ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–]
    C --> C2[é«˜åº¦é‡å­åŒ–æœ€é©åŒ–]
    C --> C3[Windows NPUæœ€é©åŒ–]
    
    D --> D1[æ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«]
    D --> D2[NPUæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«]
    D --> D3[è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰]
    
    E --> E1[ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢]
    E --> E2[æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯]
    E --> E3[æ¤œè¨¼ãƒ†ã‚¹ãƒˆ]
```

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ç’°å¢ƒæº–å‚™

#### å¿…è¦ãªç’°å¢ƒ
- **OS**: Windows 11 (22H2ä»¥é™)
- **CPU**: AMD Ryzen AI (7040/8040ã‚·ãƒªãƒ¼ã‚ºä»¥é™)
- **ãƒ¡ãƒ¢ãƒª**: 16GBä»¥ä¸Šæ¨å¥¨ï¼ˆ32GBä»¥ä¸Šã§æœ€é©ï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 50GBä»¥ä¸Šã®ç©ºãå®¹é‡

#### ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```powershell
# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
pip install torch transformers accelerate

# ONNXé–¢é€£
pip install onnx onnxruntime-vitisai

# ãã®ä»–
pip install psutil protobuf==3.20.3
```

### 2. ãƒªãƒã‚¸ãƒˆãƒªå–å¾—

```powershell
git clone https://github.com/kojima123/infer-os.git
cd infer-os
```

### 3. ç’°å¢ƒæ¤œè¨¼

```powershell
# çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ¤œè¨¼
python test_integrated_system.py

# ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
python run_integrated_demo.py --check-deps
```

### 4. åŸºæœ¬å®Ÿè¡Œ

```powershell
# çµ±åˆãƒ‡ãƒ¢å®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰
python run_integrated_demo.py

# ç›´æ¥å®Ÿè¡Œ
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --interactive
```

## ğŸ“± å¯¾å¿œãƒ¢ãƒ‡ãƒ«

### ğŸ¥‡ NPUæœ€é©åŒ–æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆæ¨å¥¨ï¼‰

#### llama3-8b-amd-npu
- **ã‚µã‚¤ã‚º**: 8Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç´„4.5GBï¼‰
- **ç‰¹å¾´**: NPUå®Œå…¨æœ€é©åŒ–æ¸ˆã¿ã€AWQé‡å­åŒ–
- **ç”¨é€”**: æ±ç”¨æ—¥æœ¬èªå¯¾è©±ã€é«˜é€Ÿæ¨è«–
- **NPUå¯¾å¿œ**: âœ… å®Œå…¨å¯¾å¿œ
- **Infer-OSå¯¾å¿œ**: âœ… å®Œå…¨å¯¾å¿œ

#### ALMA-Ja-V3-amd-npu
- **ã‚µã‚¤ã‚º**: 7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç´„4.0GBï¼‰
- **ç‰¹å¾´**: æ—¥æœ¬èªç¿»è¨³ç‰¹åŒ–ã€NPUæœ€é©åŒ–
- **ç”¨é€”**: ç¿»è¨³ã‚¿ã‚¹ã‚¯ã€å¤šè¨€èªå‡¦ç†
- **NPUå¯¾å¿œ**: âœ… å®Œå…¨å¯¾å¿œ
- **Infer-OSå¯¾å¿œ**: âœ… å®Œå…¨å¯¾å¿œ

### ğŸ¥ˆ å¤§è¦æ¨¡æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«

#### cyberagent/Llama-3.1-70B-Japanese-Instruct-2407
- **ã‚µã‚¤ã‚º**: 70Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç´„140GBï¼‰
- **ç‰¹å¾´**: æœ€é‡é‡ç´šæ—¥æœ¬èªç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«
- **ç”¨é€”**: é«˜å“è³ªãªæ—¥æœ¬èªç”Ÿæˆã€è¤‡é›‘ãªã‚¿ã‚¹ã‚¯
- **NPUå¯¾å¿œ**: ğŸ”§ ONNXå¤‰æ›å¯èƒ½
- **Infer-OSå¯¾å¿œ**: âœ… å®Œå…¨å¯¾å¿œ

#### rinna/youri-7b-chat
- **ã‚µã‚¤ã‚º**: 7Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆç´„14GBï¼‰
- **ç‰¹å¾´**: æ—¥æœ¬èªãƒãƒ£ãƒƒãƒˆç‰¹åŒ–
- **ç”¨é€”**: å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆ
- **NPUå¯¾å¿œ**: ğŸ”§ å¤‰æ›å¯èƒ½
- **Infer-OSå¯¾å¿œ**: âœ… å®Œå…¨å¯¾å¿œ

## ğŸ”§ æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰

### 1. å®Œå…¨çµ±åˆæœ€é©åŒ–ï¼ˆfullï¼‰
```powershell
python integrated_npu_infer_os.py --model llama3-8b-amd-npu
```
- âš¡ NPUæœ€é©åŒ–: âœ…
- ğŸ§  Infer-OSæœ€é©åŒ–: âœ…
- ğŸ’¾ ç©æ¥µçš„ãƒ¡ãƒ¢ãƒª: âœ…
- ğŸ“Š é«˜åº¦é‡å­åŒ–: âœ…
- ğŸªŸ Windows NPU: âœ…

**åŠ¹æœ**: æœ€é«˜ã®æ€§èƒ½ã¨åŠ¹ç‡ã‚’å®Ÿç¾

### 2. NPUæœ€é©åŒ–ã®ã¿ï¼ˆnpu_onlyï¼‰
```powershell
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --disable-infer-os
```
- âš¡ NPUæœ€é©åŒ–: âœ…
- ğŸ§  Infer-OSæœ€é©åŒ–: âŒ

**åŠ¹æœ**: NPUå‡¦ç†ã«ç‰¹åŒ–ã€ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆ

### 3. Infer-OSæœ€é©åŒ–ã®ã¿ï¼ˆinfer_os_onlyï¼‰
```powershell
python integrated_npu_infer_os.py --model rinna/youri-7b-chat --disable-npu
```
- âš¡ NPUæœ€é©åŒ–: âŒ
- ğŸ§  Infer-OSæœ€é©åŒ–: âœ…

**åŠ¹æœ**: CPU/GPUæœ€é©åŒ–ã€å¹…åºƒã„ç’°å¢ƒå¯¾å¿œ

### 4. ãƒãƒ©ãƒ³ã‚¹æœ€é©åŒ–ï¼ˆbalancedï¼‰
```powershell
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --quantization-profile balanced
```
- âš¡ NPUæœ€é©åŒ–: âœ…
- ğŸ§  Infer-OSæœ€é©åŒ–: âœ…
- ğŸ“Š é‡å­åŒ–: ãƒãƒ©ãƒ³ã‚¹è¨­å®š

**åŠ¹æœ**: å®‰å®šæ€§ã¨æ€§èƒ½ã®ãƒãƒ©ãƒ³ã‚¹

## ğŸ® ä½¿ç”¨æ–¹æ³•

### ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢

#### åŸºæœ¬å®Ÿè¡Œ
```powershell
python run_integrated_demo.py
```

å¯¾è©±å½¢å¼ã§ãƒ¢ãƒ‡ãƒ«ã€æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã€ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ªã‚’é¸æŠã§ãã¾ã™ã€‚

#### ç›´æ¥æŒ‡å®šå®Ÿè¡Œ
```powershell
# æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --interactive

# ç¿»è¨³ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«
python integrated_npu_infer_os.py --model ALMA-Ja-V3-amd-npu --interactive

# å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ï¼ˆè¦å¤§å®¹é‡ãƒ¡ãƒ¢ãƒªï¼‰
python integrated_npu_infer_os.py --model cyberagent/Llama-3.1-70B-Japanese-Instruct-2407 --interactive
```

### å˜ç™ºå®Ÿè¡Œ

```powershell
# åŸºæœ¬çš„ãªè³ªå•
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --prompt "äººå·¥çŸ¥èƒ½ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚"

# é•·æ–‡ç”Ÿæˆ
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --prompt "æ—¥æœ¬ã®å››å­£ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚" --max-tokens 300

# ç¿»è¨³ã‚¿ã‚¹ã‚¯
python integrated_npu_infer_os.py --model ALMA-Ja-V3-amd-npu --prompt "æ¬¡ã®è‹±èªã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„: 'The future of AI is bright.'"
```

### æ€§èƒ½æ¯”è¼ƒ

```powershell
# æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒ
python run_integrated_demo.py --compare

# è©³ç´°ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
python test_integrated_system.py --save-results
```

## ğŸ“Š æ€§èƒ½æœ€é©åŒ–

### NPUè² è·ç‡å‘ä¸Šã®ã‚³ãƒ„

#### 1. NPUæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
```powershell
# æ¨å¥¨: NPUå®Œå…¨å¯¾å¿œãƒ¢ãƒ‡ãƒ«
python integrated_npu_infer_os.py --model llama3-8b-amd-npu
```

#### 2. ç¶™ç¶šçš„ãªæ¨è«–å®Ÿè¡Œ
```powershell
# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã§é€£ç¶šå®Ÿè¡Œ
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --interactive
```

#### 3. é©åˆ‡ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°è¨­å®š
```powershell
# é•·ã‚ã®ãƒˆãƒ¼ã‚¯ãƒ³ç”Ÿæˆã§NPUæ´»ç”¨æ™‚é–“å»¶é•·
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --prompt "è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„" --max-tokens 200
```

### ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–

#### 1. ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–æœ‰åŠ¹åŒ–
```powershell
# å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–
python integrated_npu_infer_os.py --model cyberagent/Llama-3.1-70B-Japanese-Instruct-2407
```

#### 2. é‡å­åŒ–ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«èª¿æ•´
```powershell
# ãƒ¡ãƒ¢ãƒªé‡è¦–
python integrated_npu_infer_os.py --quantization-profile aggressive

# å“è³ªé‡è¦–
python integrated_npu_infer_os.py --quantization-profile safe
```

## ğŸ” ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

#### 1. NPUè² è·ç‡ãŒä¸ŠãŒã‚‰ãªã„

**ç—‡çŠ¶**: ã‚¿ã‚¹ã‚¯ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§NPUä½¿ç”¨ç‡0%

**åŸå› ã¨è§£æ±ºç­–**:
```powershell
# 1. VitisAI ExecutionProviderç¢ºèª
python debug_npu_info.py

# 2. NPUæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
python integrated_npu_infer_os.py --model llama3-8b-amd-npu

# 3. ç’°å¢ƒå¤‰æ•°ç¢ºèª
echo $RYZEN_AI_INSTALLATION_PATH
echo $XLNX_VART_FIRMWARE
```

#### 2. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `CUDA out of memory` ã¾ãŸã¯ `RuntimeError: out of memory`

**è§£æ±ºç­–**:
```powershell
# 1. ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–æœ‰åŠ¹åŒ–
python integrated_npu_infer_os.py --model rinna/youri-7b-chat

# 2. è»½é‡ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
python integrated_npu_infer_os.py --model ALMA-Ja-V3-amd-npu

# 3. é‡å­åŒ–å¼·åŒ–
python integrated_npu_infer_os.py --quantization-profile aggressive
```

#### 3. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—

**ç—‡çŠ¶**: `Model not found` ã¾ãŸã¯ `Connection error`

**è§£æ±ºç­–**:
```powershell
# 1. ãƒ¢ãƒ‡ãƒ«è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
python download_npu_models.py --download llama3-8b-amd-npu

# 2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèªå¾Œå†è©¦è¡Œ
python integrated_npu_infer_os.py --model llama3-8b-amd-npu

# 3. ä»£æ›¿ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
python integrated_npu_infer_os.py --model rinna/youri-7b-chat
```

#### 4. ç”Ÿæˆé€Ÿåº¦ãŒé…ã„

**ç—‡çŠ¶**: 1ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ä»¥ä¸‹ã®ç”Ÿæˆé€Ÿåº¦

**è§£æ±ºç­–**:
```powershell
# 1. NPUæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
python integrated_npu_infer_os.py --model llama3-8b-amd-npu

# 2. å®Œå…¨çµ±åˆæœ€é©åŒ–
python integrated_npu_infer_os.py --model llama3-8b-amd-npu

# 3. Windows NPUæœ€é©åŒ–ç¢ºèª
python integrated_npu_infer_os.py --model llama3-8b-amd-npu
```

### ç’°å¢ƒè¨ºæ–­

#### åŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ ãƒã‚§ãƒƒã‚¯
```powershell
# å…¨ä½“çš„ãªç’°å¢ƒè¨ºæ–­
python test_integrated_system.py

# ä¾å­˜é–¢ä¿‚ã®ã¿ãƒã‚§ãƒƒã‚¯
python run_integrated_demo.py --check-deps

# NPUç’°å¢ƒè©³ç´°ç¢ºèª
python debug_npu_info.py
```

## ğŸ“ˆ æœŸå¾…ã•ã‚Œã‚‹æ€§èƒ½

### NPUè² è·ç‡

| ãƒ¢ãƒ‡ãƒ« | æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ | NPUè² è·ç‡ | ç”Ÿæˆé€Ÿåº¦ |
|--------|-------------|-----------|----------|
| llama3-8b-amd-npu | å®Œå…¨çµ±åˆ | 20-40% | 5-10 ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ |
| ALMA-Ja-V3-amd-npu | å®Œå…¨çµ±åˆ | 15-35% | 4-8 ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ |
| rinna/youri-7b-chat | Infer-OSã®ã¿ | 0-5% | 2-5 ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ |
| Llama-3.1-70B | å®Œå…¨çµ±åˆ | 50-80% | 1-3 ãƒˆãƒ¼ã‚¯ãƒ³/ç§’ |

### ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡

| ãƒ¢ãƒ‡ãƒ« | æ¨™æº– | Infer-OSæœ€é©åŒ– | å‰Šæ¸›ç‡ |
|--------|------|----------------|--------|
| llama3-8b-amd-npu | 8GB | 4.5GB | 44% |
| ALMA-Ja-V3-amd-npu | 7GB | 4.0GB | 43% |
| rinna/youri-7b-chat | 14GB | 8GB | 43% |
| Llama-3.1-70B | 140GB | 80GB | 43% |

## ğŸ¯ ä½¿ç”¨ä¾‹

### 1. æ—¥å¸¸çš„ãªè³ªå•å¿œç­”

```powershell
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --prompt "ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚"
```

**æœŸå¾…ã•ã‚Œã‚‹å¿œç­”**:
```
ä»Šæ—¥ã®å¤©æ°—ã«ã¤ã„ã¦ãŠç­”ãˆã—ã¾ã™ã€‚ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç§ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®å¤©æ°—æƒ…å ±ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚
ç¾åœ¨ã®å¤©æ°—ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®æ–¹æ³•ã‚’ãŠå‹§ã‚ã—ã¾ã™ï¼š

1. å¤©æ°—äºˆå ±ã‚¢ãƒ—ãƒªã‚„ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ç¢ºèª
2. ãƒ†ãƒ¬ãƒ“ã‚„ãƒ©ã‚¸ã‚ªã®å¤©æ°—äºˆå ±
3. æ°—è±¡åºã®å…¬å¼ã‚µã‚¤ãƒˆ

ãŠä½ã¾ã„ã®åœ°åŸŸã®å¤©æ°—æƒ…å ±ã‚’ç¢ºèªã—ã¦ã€é©åˆ‡ãªæœè£…ã‚„å¤–å‡ºã®æº–å‚™ã‚’ã—ã¦ãã ã•ã„ã€‚
```

### 2. æŠ€è¡“çš„ãªèª¬æ˜

```powershell
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --prompt "æ©Ÿæ¢°å­¦ç¿’ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚" --max-tokens 300
```

### 3. ç¿»è¨³ã‚¿ã‚¹ã‚¯

```powershell
python integrated_npu_infer_os.py --model ALMA-Ja-V3-amd-npu --prompt "æ¬¡ã®è‹±èªã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„: 'Artificial intelligence is revolutionizing the way we work and live.'"
```

### 4. å‰µä½œãƒ»æ–‡å­¦

```powershell
python integrated_npu_infer_os.py --model llama3-8b-amd-npu --prompt "æ¡œã‚’ãƒ†ãƒ¼ãƒã«ã—ãŸçŸ­ã„è©©ã‚’ä½œã£ã¦ãã ã•ã„ã€‚"
```

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ç‹¬è‡ªãƒ¢ãƒ‡ãƒ«ã®è¿½åŠ 

#### 1. ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¿½åŠ 
`integrated_npu_infer_os.py`ã®`available_models`ã«è¿½åŠ :

```python
"your-custom-model": {
    "size": "7B",
    "type": "ã‚«ã‚¹ã‚¿ãƒ ",
    "infer_os_compatible": True,
    "npu_ready": False,
    "recommended": False,
    "description": "ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜"
}
```

#### 2. NPUæœ€é©åŒ–ã®é©ç”¨

```powershell
# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ãƒ‡ãƒ«ã§ã®å®Ÿè¡Œ
python integrated_npu_infer_os.py --model your-custom-model --interactive
```

### æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´

#### é‡å­åŒ–è¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
```python
# integrated_npu_infer_os.pyå†…ã§èª¿æ•´
quantization_config = {
    "safe": {"bits": 8, "group_size": 128},
    "balanced": {"bits": 4, "group_size": 64},
    "aggressive": {"bits": 4, "group_size": 32}
}
```

#### NPUè¨­å®šã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
```python
# NPUãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š
provider_options = {
    'VitisAIExecutionProvider': {
        'config_file': custom_config_path,
        'target': 'AMD_AIE2P_Nx4_Overlay',
        'num_of_dpu_runners': 2  # ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½
    }
}
```

## ğŸ“š API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### IntegratedNPUInferOS ã‚¯ãƒ©ã‚¹

#### åˆæœŸåŒ–
```python
system = IntegratedNPUInferOS(
    model_name="llama3-8b-amd-npu",
    enable_npu=True,
    enable_infer_os=True,
    use_aggressive_memory=True,
    use_advanced_quant=True,
    quantization_profile="balanced",
    enable_windows_npu=True
)
```

#### ä¸»è¦ãƒ¡ã‚½ãƒƒãƒ‰

##### setup_model()
```python
success = system.setup_model()
# Returns: bool - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æˆåŠŸ/å¤±æ•—
```

##### generate_text()
```python
response = system.generate_text(
    prompt="è³ªå•å†…å®¹",
    max_new_tokens=200
)
# Returns: str - ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
```

##### get_performance_stats()
```python
stats = system.get_performance_stats()
# Returns: Dict[str, Any] - æ€§èƒ½çµ±è¨ˆæƒ…å ±
```

### çµ±åˆãƒ‡ãƒ¢é–¢æ•°

#### run_integrated_demo()
```python
from run_integrated_demo import IntegratedOptimizationDemo

demo = IntegratedOptimizationDemo()
demo.run_integrated_demo(
    model_name="llama3-8b-amd-npu",
    optimization_mode="full",
    test_scenario="basic"
)
```

## ğŸš€ ä»Šå¾Œã®æ‹¡å¼µ

### è¨ˆç”»ä¸­ã®æ©Ÿèƒ½

#### 1. è¿½åŠ NPUå¯¾å¿œ
- Intel NPUå¯¾å¿œå¼·åŒ–
- Qualcomm NPUå¯¾å¿œ
- Apple Neural Engineå¯¾å¿œ

#### 2. ãƒ¢ãƒ‡ãƒ«æ‹¡å¼µ
- Phi-3æ—¥æœ¬èªç‰ˆå¯¾å¿œ
- Gemmaæ—¥æœ¬èªç‰ˆå¯¾å¿œ
- ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ”¯æ´

#### 3. æœ€é©åŒ–å¼·åŒ–
- å‹•çš„é‡å­åŒ–
- ãƒ¢ãƒ‡ãƒ«ä¸¦åˆ—å‡¦ç†
- ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ä¸¦åˆ—å‡¦ç†

#### 4. ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹æ”¹å–„
- Web UIè¿½åŠ 
- REST APIæä¾›
- Dockerå¯¾å¿œ

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

### é–‹ç™ºã¸ã®å‚åŠ 

#### 1. èª²é¡Œå ±å‘Š
- GitHub Issuesã§å•é¡Œã‚’å ±å‘Š
- è©³ç´°ãªç’°å¢ƒæƒ…å ±ã‚’å«ã‚ã‚‹
- å†ç¾æ‰‹é †ã‚’æ˜è¨˜

#### 2. æ©Ÿèƒ½ææ¡ˆ
- æ–°æ©Ÿèƒ½ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’ææ¡ˆ
- å®Ÿè£…æ–¹é‡ã‚’è­°è«–
- ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ä½œæˆ

#### 3. ã‚³ãƒ¼ãƒ‰è²¢çŒ®
- ãƒ•ã‚©ãƒ¼ã‚¯ & ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
- ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„ã®éµå®ˆ
- ãƒ†ã‚¹ãƒˆã®è¿½åŠ 

### é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```powershell
# é–‹ç™ºç‰ˆã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/kojima123/infer-os.git
cd infer-os

# é–‹ç™ºä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements-dev.txt

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python test_integrated_system.py

# æ–°æ©Ÿèƒ½é–‹ç™º
git checkout -b feature/new-feature
```

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯`LICENSE`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

### æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ

- **GitHub Issues**: https://github.com/kojima123/infer-os/issues
- **ãƒ‡ã‚£ã‚¹ã‚«ãƒƒã‚·ãƒ§ãƒ³**: https://github.com/kojima123/infer-os/discussions
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: æœ¬ã‚¬ã‚¤ãƒ‰ãŠã‚ˆã³ã‚³ãƒ¼ãƒ‰å†…ã‚³ãƒ¡ãƒ³ãƒˆ

### ã‚ˆãã‚ã‚‹è³ªå•

#### Q: NPUè² è·ç‡ãŒ2%ä»¥ä¸‹ã—ã‹ä¸ŠãŒã‚Šã¾ã›ã‚“
A: NPUæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ï¼ˆllama3-8b-amd-npuï¼‰ã‚’ä½¿ç”¨ã—ã€ç¶™ç¶šçš„ãªæ¨è«–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚éƒ¨åˆ†çš„NPUå‡¦ç†ã®ãŸã‚ã€è² è·ç‡ã¯20-40%ç¨‹åº¦ãŒæ­£å¸¸ã§ã™ã€‚

#### Q: ãƒ¡ãƒ¢ãƒªä¸è¶³ã§ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“
A: ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã‚’æœ‰åŠ¹ã«ã—ã€è»½é‡ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„ã€‚32GBä»¥ä¸Šã®ãƒ¡ãƒ¢ãƒªã‚’æ¨å¥¨ã—ã¾ã™ã€‚

#### Q: ç”Ÿæˆé€Ÿåº¦ãŒæœŸå¾…ã‚ˆã‚Šé…ã„ã§ã™
A: NPUæœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã¨å®Œå…¨çµ±åˆæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚åˆå›å®Ÿè¡Œæ™‚ã¯ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚

#### Q: VitisAI ExecutionProviderãŒåˆ©ç”¨ã§ãã¾ã›ã‚“
A: Ryzen AI SDK 1.5ä»¥é™ã¨onnxruntime-vitisaiã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã‚‚å¿…è¦ã§ã™ã€‚

---

## ğŸ‰ ã¾ã¨ã‚

**çµ±åˆNPU + Infer-OSæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ **ã«ã‚ˆã‚Šã€AMD Ryzen AI NPUã®çœŸã®åŠ›ã‚’å¼•ãå‡ºã—ã€æ—¥æœ¬èªç‰¹åŒ–LLMã§æœ€é«˜ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚

### ğŸ† ä¸»ãªæˆæœ

- âš¡ **NPUæ´»ç”¨**: VitisAI ExecutionProviderã«ã‚ˆã‚‹çœŸã®NPUå‡¦ç†
- ğŸ§  **Infer-OSçµ±åˆ**: ç©æ¥µçš„ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ã¨é«˜åº¦é‡å­åŒ–ã®çµ„ã¿åˆã‚ã›
- ğŸ‡¯ğŸ‡µ **æ—¥æœ¬èªç‰¹åŒ–**: 8B-70Bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«å¯¾å¿œ
- ğŸ“Š **åŒ…æ‹¬çš„æœ€é©åŒ–**: 4ã¤ã®æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã¨è©³ç´°ãªæ€§èƒ½ç›£è¦–
- ğŸ® **ä½¿ã„ã‚„ã™ã•**: ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ‡ãƒ¢ã¨è‡ªå‹•åŒ–æ©Ÿèƒ½

### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **ç’°å¢ƒæ§‹ç¯‰**: ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ç’°å¢ƒç¢ºèª
2. **åŸºæœ¬å®Ÿè¡Œ**: æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã§ã®å‹•ä½œç¢ºèª
3. **æœ€é©åŒ–èª¿æ•´**: ç”¨é€”ã«å¿œã˜ãŸæœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰ã®é¸æŠ
4. **æ€§èƒ½æ¸¬å®š**: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã‚ˆã‚‹åŠ¹æœç¢ºèª
5. **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**: ç‹¬è‡ªè¦ä»¶ã«å¿œã˜ãŸèª¿æ•´

**çœŸã®åŒ…æ‹¬çš„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã§ã€NPUã®å¯èƒ½æ€§ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ã¦ãã ã•ã„ï¼**


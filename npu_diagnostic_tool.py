#!/usr/bin/env python3
"""
NPUçŠ¶æ…‹è¨ºæ–­ãƒ„ãƒ¼ãƒ«
å†èµ·å‹•å¾Œã®NPUå•é¡Œã‚’è¨ºæ–­ã—ã€å¾©æ—§æ–¹æ³•ã‚’ææ¡ˆã™ã‚‹
"""

import sys
import subprocess
import json
import time
from typing import Dict, List, Any

try:
    import onnxruntime as ort
    ONNXRUNTIME_AVAILABLE = True
except ImportError:
    ONNXRUNTIME_AVAILABLE = False

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

class NPUDiagnosticTool:
    def __init__(self):
        self.results = {}
        
    def run_full_diagnosis(self) -> Dict[str, Any]:
        """å®Œå…¨ãªNPUè¨ºæ–­ã‚’å®Ÿè¡Œ"""
        print("ğŸ” NPUçŠ¶æ…‹è¨ºæ–­ãƒ„ãƒ¼ãƒ«é–‹å§‹")
        print("=" * 60)
        
        # 1. ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«è¨ºæ–­
        print("\nğŸ“‹ 1. ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«è¨ºæ–­")
        self.results['system'] = self.diagnose_system_level()
        
        # 2. DirectMLè¨ºæ–­
        print("\nğŸ”§ 2. DirectMLè¨ºæ–­")
        self.results['directml'] = self.diagnose_directml()
        
        # 3. ONNX Runtimeè¨ºæ–­
        print("\nâš™ï¸ 3. ONNX Runtimeè¨ºæ–­")
        self.results['onnxruntime'] = self.diagnose_onnxruntime()
        
        # 4. ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§è¨ºæ–­
        print("\nğŸ’» 4. ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§è¨ºæ–­")
        self.results['devices'] = self.diagnose_devices()
        
        # 5. å¾©æ—§ææ¡ˆ
        print("\nğŸ”§ 5. å¾©æ—§ææ¡ˆ")
        self.results['recovery'] = self.suggest_recovery()
        
        # 6. è¨ºæ–­çµæœã‚µãƒãƒªãƒ¼
        print("\nğŸ“Š 6. è¨ºæ–­çµæœã‚µãƒãƒªãƒ¼")
        self.print_summary()
        
        return self.results
    
    def diagnose_system_level(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®NPUè¨ºæ–­"""
        result = {
            'npu_devices': [],
            'device_manager_status': 'unknown',
            'driver_status': 'unknown'
        }
        
        try:
            # ãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼æƒ…å ±å–å¾—ï¼ˆPowerShellçµŒç”±ï¼‰
            print("  ğŸ” ãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ç¢ºèªä¸­...")
            
            # NPUãƒ‡ãƒã‚¤ã‚¹æ¤œç´¢
            powershell_cmd = '''
            Get-PnpDevice | Where-Object {
                $_.FriendlyName -like "*NPU*" -or 
                $_.FriendlyName -like "*Neural*" -or
                $_.FriendlyName -like "*AI*" -or
                $_.HardwareID -like "*NPU*"
            } | Select-Object FriendlyName, Status, InstanceId | ConvertTo-Json
            '''
            
            try:
                proc = subprocess.run(
                    ['powershell', '-Command', powershell_cmd],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                
                if proc.returncode == 0 and proc.stdout.strip():
                    devices = json.loads(proc.stdout)
                    if isinstance(devices, dict):
                        devices = [devices]
                    
                    result['npu_devices'] = devices
                    result['device_manager_status'] = 'success'
                    
                    print(f"    âœ… NPUãƒ‡ãƒã‚¤ã‚¹ç™ºè¦‹: {len(devices)}å€‹")
                    for device in devices:
                        print(f"      ğŸ“± {device.get('FriendlyName', 'Unknown')}: {device.get('Status', 'Unknown')}")
                else:
                    result['device_manager_status'] = 'no_devices'
                    print("    âš ï¸ NPUãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    
            except subprocess.TimeoutExpired:
                result['device_manager_status'] = 'timeout'
                print("    âŒ ãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ç¢ºèªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except json.JSONDecodeError:
                result['device_manager_status'] = 'parse_error'
                print("    âŒ ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã®è§£æã«å¤±æ•—")
            except Exception as e:
                result['device_manager_status'] = f'error: {e}'
                print(f"    âŒ ãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
                
        except Exception as e:
            result['device_manager_status'] = f'system_error: {e}'
            print(f"    âŒ ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def diagnose_directml(self) -> Dict[str, Any]:
        """DirectMLè¨ºæ–­"""
        result = {
            'available': False,
            'version': 'unknown',
            'devices': [],
            'error': None
        }
        
        try:
            print("  ğŸ” DirectMLçŠ¶æ…‹ç¢ºèªä¸­...")
            
            # DirectMLã®åŸºæœ¬ç¢ºèª
            try:
                import onnxruntime as ort
                
                # DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®åˆ©ç”¨å¯èƒ½æ€§ç¢ºèª
                available_providers = ort.get_available_providers()
                
                if 'DmlExecutionProvider' in available_providers:
                    result['available'] = True
                    print("    âœ… DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ©ç”¨å¯èƒ½")
                    
                    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
                    result['version'] = ort.__version__
                    print(f"    ğŸ“‹ ONNX Runtime ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {ort.__version__}")
                    
                    # ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±å–å¾—è©¦è¡Œ
                    try:
                        # ç°¡å˜ãªã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆã§ãƒ‡ãƒã‚¤ã‚¹ç¢ºèª
                        providers = [('DmlExecutionProvider', {'device_id': 0})]
                        
                        # ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ
                        import numpy as np
                        from onnx import helper, TensorProto
                        
                        # æœ€å°é™ã®ONNXãƒ¢ãƒ‡ãƒ«ä½œæˆ
                        input_tensor = helper.make_tensor_value_info('input', TensorProto.FLOAT, [1, 1])
                        output_tensor = helper.make_tensor_value_info('output', TensorProto.FLOAT, [1, 1])
                        
                        identity_node = helper.make_node('Identity', inputs=['input'], outputs=['output'])
                        graph = helper.make_graph([identity_node], 'test', [input_tensor], [output_tensor])
                        model = helper.make_model(graph)
                        model.ir_version = 6
                        model.opset_import[0].version = 9
                        
                        session = ort.InferenceSession(
                            model.SerializeToString(),
                            providers=providers
                        )
                        
                        active_providers = session.get_providers()
                        result['devices'] = active_providers
                        
                        print(f"    ğŸ“± ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {active_providers}")
                        
                        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                        test_input = np.array([[1.0]], dtype=np.float32)
                        test_output = session.run(['output'], {'input': test_input})
                        
                        print("    âœ… DirectMLãƒ†ã‚¹ãƒˆå®Ÿè¡ŒæˆåŠŸ")
                        
                    except Exception as device_error:
                        result['error'] = f'device_test_failed: {device_error}'
                        print(f"    âš ï¸ DirectMLãƒ‡ãƒã‚¤ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {device_error}")
                        
                else:
                    result['available'] = False
                    print("    âŒ DirectMLãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆ©ç”¨ä¸å¯")
                    print(f"    ğŸ“‹ åˆ©ç”¨å¯èƒ½ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {available_providers}")
                    
            except ImportError:
                result['error'] = 'onnxruntime_not_available'
                print("    âŒ ONNX Runtime ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            except Exception as e:
                result['error'] = f'directml_error: {e}'
                print(f"    âŒ DirectMLç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
                
        except Exception as e:
            result['error'] = f'diagnosis_error: {e}'
            print(f"    âŒ DirectMLè¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def diagnose_onnxruntime(self) -> Dict[str, Any]:
        """ONNX Runtimeè¨ºæ–­"""
        result = {
            'installed': ONNXRUNTIME_AVAILABLE,
            'version': 'unknown',
            'providers': [],
            'directml_support': False
        }
        
        if ONNXRUNTIME_AVAILABLE:
            try:
                import onnxruntime as ort
                
                result['version'] = ort.__version__
                result['providers'] = ort.get_available_providers()
                result['directml_support'] = 'DmlExecutionProvider' in result['providers']
                
                print(f"    âœ… ONNX Runtime: {ort.__version__}")
                print(f"    ğŸ“‹ åˆ©ç”¨å¯èƒ½ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {len(result['providers'])}å€‹")
                for provider in result['providers']:
                    status = "âœ…" if provider == 'DmlExecutionProvider' else "ğŸ“‹"
                    print(f"      {status} {provider}")
                    
            except Exception as e:
                result['error'] = str(e)
                print(f"    âŒ ONNX Runtimeè¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print("    âŒ ONNX Runtime ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        return result
    
    def diagnose_devices(self) -> Dict[str, Any]:
        """ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§è¨ºæ–­"""
        result = {
            'gpu_devices': [],
            'npu_devices': [],
            'total_devices': 0
        }
        
        try:
            print("  ğŸ” è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ç¢ºèªä¸­...")
            
            # GPUæƒ…å ±å–å¾—
            if TORCH_AVAILABLE:
                try:
                    import torch
                    
                    if torch.cuda.is_available():
                        gpu_count = torch.cuda.device_count()
                        result['gpu_devices'] = []
                        
                        for i in range(gpu_count):
                            gpu_info = {
                                'id': i,
                                'name': torch.cuda.get_device_name(i),
                                'memory': torch.cuda.get_device_properties(i).total_memory
                            }
                            result['gpu_devices'].append(gpu_info)
                            
                        print(f"    ğŸ® GPUç™ºè¦‹: {gpu_count}å€‹")
                        for gpu in result['gpu_devices']:
                            memory_gb = gpu['memory'] / (1024**3)
                            print(f"      ğŸ“± GPU {gpu['id']}: {gpu['name']} ({memory_gb:.1f}GB)")
                    else:
                        print("    âš ï¸ CUDAå¯¾å¿œGPUãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        
                except Exception as e:
                    print(f"    âŒ GPUæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            
            # NPUæƒ…å ±ã¯å‰ã®ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­çµæœã‚’å‚ç…§
            if 'system' in self.results:
                result['npu_devices'] = self.results['system'].get('npu_devices', [])
            
            result['total_devices'] = len(result['gpu_devices']) + len(result['npu_devices'])
            
        except Exception as e:
            print(f"    âŒ ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
        
        return result
    
    def suggest_recovery(self) -> Dict[str, Any]:
        """å¾©æ—§æ–¹æ³•ã®ææ¡ˆ"""
        suggestions = []
        priority = 'low'
        
        # DirectMLå•é¡Œã®å ´åˆ
        if not self.results.get('directml', {}).get('available', False):
            suggestions.append({
                'issue': 'DirectMLåˆ©ç”¨ä¸å¯',
                'solution': 'ONNX Runtime (DirectMLç‰ˆ) ã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«',
                'command': 'pip uninstall onnxruntime && pip install onnxruntime-directml',
                'priority': 'high'
            })
            priority = 'high'
        
        # NPUãƒ‡ãƒã‚¤ã‚¹èªè­˜å•é¡Œã®å ´åˆ
        npu_devices = self.results.get('system', {}).get('npu_devices', [])
        if not npu_devices:
            suggestions.append({
                'issue': 'NPUãƒ‡ãƒã‚¤ã‚¹æœªèªè­˜',
                'solution': 'NPUãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«',
                'command': 'ãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§NPUãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æ›´æ–°',
                'priority': 'high'
            })
            priority = 'high'
        
        # ãƒ‡ãƒã‚¤ã‚¹çŠ¶æ…‹å•é¡Œã®å ´åˆ
        for device in npu_devices:
            if device.get('Status') != 'OK':
                suggestions.append({
                    'issue': f'NPUãƒ‡ãƒã‚¤ã‚¹çŠ¶æ…‹ç•°å¸¸: {device.get("Status")}',
                    'solution': 'ãƒ‡ãƒã‚¤ã‚¹ã®ç„¡åŠ¹åŒ–â†’æœ‰åŠ¹åŒ–',
                    'command': 'ãƒ‡ãƒã‚¤ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã§ãƒ‡ãƒã‚¤ã‚¹ã‚’ç„¡åŠ¹åŒ–å¾Œã€å†æœ‰åŠ¹åŒ–',
                    'priority': 'medium'
                })
                if priority == 'low':
                    priority = 'medium'
        
        # ä¸€èˆ¬çš„ãªå¾©æ—§æ–¹æ³•
        suggestions.append({
            'issue': 'ä¸€èˆ¬çš„ãªå¾©æ—§',
            'solution': 'ã‚·ã‚¹ãƒ†ãƒ å†èµ·å‹•',
            'command': 'shutdown /r /t 0',
            'priority': 'low'
        })
        
        # ææ¡ˆã®è¡¨ç¤º
        print(f"  ğŸ”§ å¾©æ—§ææ¡ˆ (å„ªå…ˆåº¦: {priority})")
        for i, suggestion in enumerate(suggestions, 1):
            print(f"    {i}. {suggestion['issue']}")
            print(f"       ğŸ’¡ è§£æ±ºæ–¹æ³•: {suggestion['solution']}")
            print(f"       ğŸ“ ã‚³ãƒãƒ³ãƒ‰: {suggestion['command']}")
            print(f"       âš¡ å„ªå…ˆåº¦: {suggestion['priority']}")
            print()
        
        return {
            'suggestions': suggestions,
            'priority': priority,
            'count': len(suggestions)
        }
    
    def print_summary(self):
        """è¨ºæ–­çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º"""
        print("ğŸ“Š è¨ºæ–­çµæœã‚µãƒãƒªãƒ¼")
        print("-" * 40)
        
        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        system = self.results.get('system', {})
        npu_count = len(system.get('npu_devices', []))
        print(f"ğŸ–¥ï¸  ã‚·ã‚¹ãƒ†ãƒ : NPUãƒ‡ãƒã‚¤ã‚¹ {npu_count}å€‹")
        
        # DirectMLçŠ¶æ…‹
        directml = self.results.get('directml', {})
        directml_status = "âœ… åˆ©ç”¨å¯èƒ½" if directml.get('available') else "âŒ åˆ©ç”¨ä¸å¯"
        print(f"ğŸ”§ DirectML: {directml_status}")
        
        # ONNX RuntimeçŠ¶æ…‹
        onnxrt = self.results.get('onnxruntime', {})
        onnxrt_status = "âœ… ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿" if onnxrt.get('installed') else "âŒ æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
        print(f"âš™ï¸  ONNX Runtime: {onnxrt_status}")
        
        # å¾©æ—§ææ¡ˆ
        recovery = self.results.get('recovery', {})
        suggestion_count = recovery.get('count', 0)
        priority = recovery.get('priority', 'unknown')
        print(f"ğŸ”§ å¾©æ—§ææ¡ˆ: {suggestion_count}å€‹ (å„ªå…ˆåº¦: {priority})")
        
        # ç·åˆåˆ¤å®š
        if directml.get('available') and npu_count > 0:
            print("\nğŸ¯ ç·åˆåˆ¤å®š: âœ… NPUä½¿ç”¨å¯èƒ½")
        elif directml.get('available'):
            print("\nğŸ¯ ç·åˆåˆ¤å®š: âš ï¸ DirectMLåˆ©ç”¨å¯èƒ½ã€NPUè¦ç¢ºèª")
        else:
            print("\nğŸ¯ ç·åˆåˆ¤å®š: âŒ NPUä½¿ç”¨ä¸å¯ã€å¾©æ—§ãŒå¿…è¦")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    diagnostic = NPUDiagnosticTool()
    results = diagnostic.run_full_diagnosis()
    
    # çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    try:
        with open('npu_diagnostic_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ è¨ºæ–­çµæœã‚’ npu_diagnostic_results.json ã«ä¿å­˜ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ è¨ºæ–­çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()

